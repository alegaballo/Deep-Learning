{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1 style=\"text-align:center\">Deep Learning   </h1>\n",
    "<h1 style=\"text-align:center\"> Lab Session 2 - 3 Hours </h1>\n",
    "<h1 style=\"text-align:center\"> Convolutional Neural Network (CNN) for Handwritten Digits Recognition</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Student 1:</b> # Gaballo Alessandro\n",
    "<b> Student 2:</b> # Wacker Jonas\n",
    " \n",
    " \n",
    "The aim of this session is to practice with Convolutional Neural Networks. Answers and experiments should be made by groups of one or two students. Each group should fill and run appropriate notebook cells. \n",
    "\n",
    "\n",
    "Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an pdf document using print as PDF (Ctrl+P). Do not forget to run all your cells before generating your final report and do not forget to include the names of all participants in the group. The lab session should be completed by May 29th 2017.\n",
    "\n",
    "Send you pdf file to benoit.huet@eurecom.fr and olfa.ben-ahmed@eurecom.fr using **[DeepLearning_lab2]** as Subject of your email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the last Lab Session, you built a Multilayer Perceptron for recognizing hand-written digits from the MNIST data-set. The best achieved accuracy on testing data was about 97%.  Can  you do better than these results using a deep CNN ?\n",
    "In this Lab Session, you will build, train and optimize in TensorFlow one of the early Convolutional Neural Networks:  **LeNet-5** to go to  more than 99% of accuracy. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load MNIST Data in TensorFlow\n",
    "Run the cell above to load the MNIST data that comes  with TensorFlow. You will use this data in **Section 1** and **Section 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Image Shape: (784,)\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "X_train, y_train           = mnist.train.images, mnist.train.labels\n",
    "X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test             = mnist.test.images, mnist.test.labels\n",
    "print(\"Image Shape: {}\".format(X_train[0].shape))\n",
    "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
    "print(\"Test Set:       {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 1 : My First Model in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Before starting with CNN, let's train and test in TensorFlow the example :\n",
    "**y=softmax(Wx+b)** seen in the DeepLearing course last week. \n",
    "\n",
    "This model reaches an accuracy of about 92 %.\n",
    "You will also learn how to launch the tensorBoard https://www.tensorflow.org/get_started/summaries_and_tensorboard to  visualize the computation graph, statistics and learning curves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Part 1 </b> : Read carefully the code in the cell below. Run it to perform training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  01   =====> Loss= 1.288867864\n",
      "Epoch:  02   =====> Loss= 0.733035091\n",
      "Epoch:  03   =====> Loss= 0.600288722\n",
      "Epoch:  04   =====> Loss= 0.536401708\n",
      "Epoch:  05   =====> Loss= 0.498107379\n",
      "Epoch:  06   =====> Loss= 0.470978013\n",
      "Epoch:  07   =====> Loss= 0.451188578\n",
      "Epoch:  08   =====> Loss= 0.436120835\n",
      "Epoch:  09   =====> Loss= 0.423948135\n",
      "Epoch:  10   =====> Loss= 0.413557586\n",
      "Epoch:  11   =====> Loss= 0.404378581\n",
      "Epoch:  12   =====> Loss= 0.396322768\n",
      "Epoch:  13   =====> Loss= 0.389684460\n",
      "Epoch:  14   =====> Loss= 0.384512511\n",
      "Epoch:  15   =====> Loss= 0.378820851\n",
      "Epoch:  16   =====> Loss= 0.375883290\n",
      "Epoch:  17   =====> Loss= 0.369544002\n",
      "Epoch:  18   =====> Loss= 0.367543612\n",
      "Epoch:  19   =====> Loss= 0.362105399\n",
      "Epoch:  20   =====> Loss= 0.359983072\n",
      "Epoch:  21   =====> Loss= 0.355285205\n",
      "Epoch:  22   =====> Loss= 0.354059463\n",
      "Epoch:  23   =====> Loss= 0.351495637\n",
      "Epoch:  24   =====> Loss= 0.349211966\n",
      "Epoch:  25   =====> Loss= 0.346712716\n",
      "Epoch:  26   =====> Loss= 0.344755582\n",
      "Epoch:  27   =====> Loss= 0.341206301\n",
      "Epoch:  28   =====> Loss= 0.339361045\n",
      "Epoch:  29   =====> Loss= 0.338260012\n",
      "Epoch:  30   =====> Loss= 0.337416410\n",
      "Epoch:  31   =====> Loss= 0.334402409\n",
      "Epoch:  32   =====> Loss= 0.333537977\n",
      "Epoch:  33   =====> Loss= 0.333487738\n",
      "Epoch:  34   =====> Loss= 0.328756334\n",
      "Epoch:  35   =====> Loss= 0.329146579\n",
      "Epoch:  36   =====> Loss= 0.329469574\n",
      "Epoch:  37   =====> Loss= 0.324617895\n",
      "Epoch:  38   =====> Loss= 0.327903109\n",
      "Epoch:  39   =====> Loss= 0.323044734\n",
      "Epoch:  40   =====> Loss= 0.322069841\n",
      "Epoch:  41   =====> Loss= 0.323246439\n",
      "Epoch:  42   =====> Loss= 0.320546922\n",
      "Epoch:  43   =====> Loss= 0.320894253\n",
      "Epoch:  44   =====> Loss= 0.317948107\n",
      "Epoch:  45   =====> Loss= 0.318080398\n",
      "Epoch:  46   =====> Loss= 0.317362373\n",
      "Epoch:  47   =====> Loss= 0.315915486\n",
      "Epoch:  48   =====> Loss= 0.314671525\n",
      "Epoch:  49   =====> Loss= 0.314684657\n",
      "Epoch:  50   =====> Loss= 0.313388246\n",
      "Epoch:  51   =====> Loss= 0.314307040\n",
      "Epoch:  52   =====> Loss= 0.312222170\n",
      "Epoch:  53   =====> Loss= 0.310096024\n",
      "Epoch:  54   =====> Loss= 0.312088087\n",
      "Epoch:  55   =====> Loss= 0.308844715\n",
      "Epoch:  56   =====> Loss= 0.308079545\n",
      "Epoch:  57   =====> Loss= 0.308560274\n",
      "Epoch:  58   =====> Loss= 0.310012550\n",
      "Epoch:  59   =====> Loss= 0.306122613\n",
      "Epoch:  60   =====> Loss= 0.306868705\n",
      "Epoch:  61   =====> Loss= 0.306243087\n",
      "Epoch:  62   =====> Loss= 0.306501232\n",
      "Epoch:  63   =====> Loss= 0.305206700\n",
      "Epoch:  64   =====> Loss= 0.302598785\n",
      "Epoch:  65   =====> Loss= 0.305579692\n",
      "Epoch:  66   =====> Loss= 0.303031089\n",
      "Epoch:  67   =====> Loss= 0.303351414\n",
      "Epoch:  68   =====> Loss= 0.300520867\n",
      "Epoch:  69   =====> Loss= 0.302340939\n",
      "Epoch:  70   =====> Loss= 0.301012290\n",
      "Epoch:  71   =====> Loss= 0.302096454\n",
      "Epoch:  72   =====> Loss= 0.300137477\n",
      "Epoch:  73   =====> Loss= 0.299579867\n",
      "Epoch:  74   =====> Loss= 0.299648775\n",
      "Epoch:  75   =====> Loss= 0.295524285\n",
      "Epoch:  76   =====> Loss= 0.301395969\n",
      "Epoch:  77   =====> Loss= 0.297791887\n",
      "Epoch:  78   =====> Loss= 0.296151120\n",
      "Epoch:  79   =====> Loss= 0.300151270\n",
      "Epoch:  80   =====> Loss= 0.294682694\n",
      "Epoch:  81   =====> Loss= 0.295737689\n",
      "Epoch:  82   =====> Loss= 0.297138908\n",
      "Epoch:  83   =====> Loss= 0.293139303\n",
      "Epoch:  84   =====> Loss= 0.297382911\n",
      "Epoch:  85   =====> Loss= 0.294834199\n",
      "Epoch:  86   =====> Loss= 0.294794534\n",
      "Epoch:  87   =====> Loss= 0.292691043\n",
      "Epoch:  88   =====> Loss= 0.296119893\n",
      "Epoch:  89   =====> Loss= 0.293497539\n",
      "Epoch:  90   =====> Loss= 0.291858540\n",
      "Epoch:  91   =====> Loss= 0.290854802\n",
      "Epoch:  92   =====> Loss= 0.296087456\n",
      "Epoch:  93   =====> Loss= 0.289536913\n",
      "Epoch:  94   =====> Loss= 0.294090118\n",
      "Epoch:  95   =====> Loss= 0.290013390\n",
      "Epoch:  96   =====> Loss= 0.291925661\n",
      "Epoch:  97   =====> Loss= 0.290943413\n",
      "Epoch:  98   =====> Loss= 0.293690464\n",
      "Epoch:  99   =====> Loss= 0.287999376\n",
      "Epoch:  100   =====> Loss= 0.288455339\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9205\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#STEP 1\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "logs_path = 'log_files/'  # useful for tensorboard\n",
    "\n",
    "# tf Graph Input:  mnist data image of shape 28*28=784\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='InputData')\n",
    "# 0-9 digits recognition,  10 classes\n",
    "y = tf.placeholder(tf.float32, [None, 10], name='LabelData')\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([784, 10]), name='Weights')\n",
    "b = tf.Variable(tf.zeros([10]), name='Bias')\n",
    "\n",
    "# Construct model and encapsulating all ops into scopes, making Tensorboard's Graph visualization more convenient\n",
    "with tf.name_scope('Model'):\n",
    "    # Model\n",
    "    pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "with tf.name_scope('Loss'):\n",
    "    # Minimize error using cross entropy\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "with tf.name_scope('SGD'):\n",
    "    # Gradient Descent\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "with tf.name_scope('Accuracy'):\n",
    "    # Accuracy\n",
    "    acc = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"Loss\", cost)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"Accuracy\", acc)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "#STEP 2 \n",
    "\n",
    "\n",
    "# Launch the graph for training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop), cost op (to get loss value)\n",
    "            # and summary nodes\n",
    "            _, c, summary = sess.run([optimizer, cost, merged_summary_op],\n",
    "                                     feed_dict={x: batch_xs, y: batch_ys})\n",
    "            # Write logs at every iteration\n",
    "            summary_writer.add_summary(summary, epoch * total_batch + i)\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print(\"Epoch: \", '%02d' % (epoch+1), \"  =====> Loss=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    # Calculate accuracy\n",
    "    print(\"Accuracy:\", acc.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Part 2  </b>: Using Tensorboard, we can  now visualize the created graph, giving you an overview of your architecture and how all of the major components  are connected. You can also see and analyse the learning curves. \n",
    "\n",
    "To launch tensorBoard: \n",
    "- Go to the **TP2** folder, \n",
    "- Open a Terminal and run the command line **\"tensorboard --logdir log_files/\"**, it will generate an http link ,ex http://666.6.6.6:6006,\n",
    "- Copy this  link into your web browser \n",
    "\n",
    "\n",
    "Enjoy It !! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 2 : The 99% MNIST Challenge !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Part 1 </b> : LeNet5 implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One you are now familar with **tensorFlow** and **tensorBoard**, you are in this section to build, train and test the baseline [LeNet-5](http://yann.lecun.com/exdb/lenet/)  model for the MNIST digits recognition problem.  \n",
    "\n",
    "In more advanced step you will make some optimizations to get more than 99% of accuracy. The best model can get to over 99.7% accuracy! \n",
    "\n",
    "For more information, have a look at this list of results : http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "<img src=\"lenet.png\",width=\"800\" height=\"600\" align=\"center\">\n",
    "<center><span>Figure 1: Lenet 5 </span></center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "--------------------------\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6 **Activation.** sigmoid **Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16. **Activation.** sigmoid **Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D.  You may need to use **flatten*  from tensorflow.contrib.layers import flatten\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs. **Activation.** sigmoid\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs. **Activation.** sigmoid\n",
    "\n",
    "**Layer 5: Fully Connected.** This should have 10 outputs. **Activation.** softmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.1.1 </b>  Implement the Neural Network architecture described above.\n",
    "For that, your will use classes and functions from  https://www.tensorflow.org/api_docs/python/tf/nn. \n",
    "\n",
    "We give you some helper functions for weigths and bias initilization. Also you can refer to section 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Helper functions  for weigths and bias initilization \n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def LeNet5_Model(data, activation='sigmoid'):    \n",
    "    # --- level 1 --- #\n",
    "    #A 4-D tensor of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "    # in_channels depens on the input img, out_channels is the number of desired filters\n",
    "    filters_conv_1 = weight_variable([5, 5, 1, 6])\n",
    "    window_pool_1 = [1, 2, 2, 1]\n",
    "    strides_conv_1 = [1, 1, 1, 1]\n",
    "    strides_pool_1 = [1, 2, 2, 1]\n",
    "    #the bias term is applied to each feature map\n",
    "    bias_layer_1 = bias_variable([6])\n",
    "    #we use SAME as padding because we want to keep the size of the original img 28x28,\n",
    "    #NOT 32x32 as expected\n",
    "    conv_layer_1 = tf.nn.conv2d(data, filters_conv_1, strides_conv_1, \"SAME\")\n",
    "    if activation=='relu':\n",
    "        hidden_layer_1 = tf.nn.relu(conv_layer_1 + bias_layer_1)\n",
    "    else:\n",
    "        hidden_layer_1 = tf.nn.sigmoid(conv_layer_1 + bias_layer_1)\n",
    "    pool_layer_1 = tf.nn.max_pool(hidden_layer_1, window_pool_1, strides_pool_1, \"VALID\")\n",
    "    \n",
    "    # --- end level 1 --- #\n",
    "    # --- level 2 --- #\n",
    "    filters_conv_2 = weight_variable([5, 5, 6, 16])\n",
    "    bias_layer_2 = bias_variable([16])\n",
    "    strides_conv_2 = [1, 1, 1, 1]\n",
    "    strides_pool_2 = [1, 2, 2, 1]\n",
    "    window_pool_2 = [1, 2, 2, 1]\n",
    "    strides_pool_2 = [1, 2, 2, 1]\n",
    "    \n",
    "    conv_layer_2 = tf.nn.conv2d(pool_layer_1, filters_conv_2, strides_conv_2, \"VALID\")\n",
    "    if activation=='relu':\n",
    "        hidden_layer_2 = tf.nn.relu(conv_layer_2 + bias_layer_2)\n",
    "    else:\n",
    "        hidden_layer_2 = tf.nn.sigmoid(conv_layer_2 + bias_layer_2)\n",
    "    pool_layer_2 = tf.nn.max_pool(hidden_layer_2, window_pool_2, strides_pool_2, \"VALID\")\n",
    "    flatten_l2 = tf.contrib.layers.flatten(pool_layer_2)\n",
    "    # --- end level 2 --- #\n",
    "\n",
    "    # --- level 3 --- #\n",
    "    l3_weights = weight_variable([16*5*5, 120])\n",
    "    l3_bias = bias_variable([120])\n",
    "    if activation=='relu':\n",
    "        hidden_layer_3 = tf.nn.relu(tf.matmul(flatten_l2, l3_weights) + l3_bias)\n",
    "    else:\n",
    "        hidden_layer_3 = tf.nn.sigmoid(tf.matmul(flatten_l2, l3_weights) + l3_bias)     \n",
    "    # --- end level 3 --- #\n",
    "    \n",
    "    # --- dropout layer --- #\n",
    "    drop_layer_1 = tf.nn.dropout(hidden_layer_3, keep_prob)\n",
    "    # --- end dropout layer --- #\n",
    "    \n",
    "    # --- level 4 --- #\n",
    "    l4_weights = weight_variable([120,84])\n",
    "    l4_bias = bias_variable([84])\n",
    "    if activation=='relu':\n",
    "        hidden_layer_4 = tf.nn.relu(tf.matmul(drop_layer_1, l4_weights) + l4_bias) \n",
    "    else:\n",
    "        hidden_layer_4 = tf.nn.sigmoid(tf.matmul(drop_layer_1, l4_weights) + l4_bias) \n",
    "    # --- end level 4 --- #\n",
    "    \n",
    "    # --- dropout layer --- #\n",
    "    drop_layer_2 = tf.nn.dropout(hidden_layer_4, keep_prob)\n",
    "    # --- end dropout layer --- #\n",
    "    \n",
    "    # --- level 5 --- #\n",
    "    l5_weights = weight_variable([84, 10])\n",
    "    l5_bias = bias_variable([10])\n",
    "    output = tf.nn.softmax(tf.matmul(drop_layer_2, l5_weights) + l5_bias)\n",
    "    # output = tf.matmul(hidden_layer_4, l5_weights) + l5_bias\n",
    "    # --- end level 5 --- #\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.1.2. </b>  Calculate the number of parameters of this model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters : 59706\n"
     ]
    }
   ],
   "source": [
    "layer_1 = 6*5*5 + 6\n",
    "layer_2 = 16*5*5 + 16\n",
    "layer_3 = 16*5*5*120 + 120\n",
    "layer_4 = 120*84 + 84\n",
    "layer_5 = 84*10 + 10\n",
    "\n",
    "total = layer_1 + layer_2 + layer_3 + layer_4 + layer_5\n",
    "print(\"Total number of parameters : %d\" %total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.1.3. </b>  Start the training with the parameters cited below:\n",
    "\n",
    "     Learning rate = 0.1\n",
    "     Loss function : Cross entropy\n",
    "     Optimisateur: SGD\n",
    "     Number of training iterations = 10000\n",
    "     The batch size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training parameters \n",
    "learning_rate = 0.1\n",
    "iterations = 100\n",
    "batch_size = 128\n",
    "logs_path = 'log_files_leNet5/'\n",
    "#Your implementation goes here\n",
    "# tf Graph Input:  mnist data image of shape 28*28=784\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1], name='InputData')\n",
    "# 0-9 digits recognition,  10 classes\n",
    "y = tf.placeholder(tf.float32, [None, 10], name='LabelData')\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.1.4. </b>  Implement the evaluation function for accuracy computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, y):\n",
    "    #your implementation goes here\n",
    "    correct_prediction = tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.1.5. </b>  Implement training pipeline and run the training data through it to train the model.\n",
    "\n",
    "- Before each epoch, shuffle the training set. \n",
    "- Print the loss per mini batch and the training/validation accuracy per epoch. (Display results every 100 epochs)\n",
    "- Save the model after training\n",
    "- Print after training the final testing accuracy \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "def train(out_dir, optimizer='GradientDescent', display_step=1, activation='sigmoid', kp=1.0):\n",
    "    \n",
    "    # Initializing the session\n",
    "    optimizers = {'GradientDescent': tf.train.GradientDescentOptimizer,\n",
    "                 'AdamOptimizer': tf.train.AdamOptimizer}\n",
    "    \n",
    "    # Construct model and encapsulating all ops into scopes, making Tensorboard's Graph visualization more convenient\n",
    "    with tf.name_scope('Model'):\n",
    "    # Model\n",
    "        pred = LeNet5_Model(x, activation)\n",
    "    with tf.name_scope('Loss'):\n",
    "    # Minimize error using cross entropy\n",
    "        #cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "        cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "    with tf.name_scope('SGD'):\n",
    "    # Gradient Descent\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "        optimizer = optimizers[optimizer](learning_rate).minimize(cost)\n",
    "    with tf.name_scope('Accuracy'):\n",
    "    # Accuracy\n",
    "        acc = evaluate(pred, y)\n",
    "    \n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    # Create a summary to monitor cost tensor\n",
    "    tf.summary.scalar(\"Loss\", cost)\n",
    "    # Create a summary to monitor accuracy tensor\n",
    "    tf.summary.scalar(\"Accuracy\", acc)\n",
    "    # Merge all summaries into a single op\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "    x_val, y_val = mnist.validation.images.reshape(-1, 28, 28, 1), mnist.validation.labels\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "        print (\"Start Training!\")\n",
    "        for epoch in range(iterations):\n",
    "            avg_cost = 0.\n",
    "            num_batch = int(mnist.train.num_examples/batch_size)\n",
    "            for i in range(num_batch):\n",
    "                # shuffle = True is the default option, the shuffle is done at each epoch\n",
    "                batch_xs, batch_ys = mnist.train.next_batch(batch_size, shuffle=True)\n",
    "                batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "\n",
    "                _, c, summary = sess.run([optimizer, cost, merged_summary_op],\n",
    "                                         feed_dict={x: batch_xs, y: batch_ys, keep_prob: kp})\n",
    "                # Write logs at every iteration\n",
    "                summary_writer.add_summary(summary, epoch * num_batch + i)\n",
    "                avg_cost += c / num_batch\n",
    "                    \n",
    "            if (epoch+1) % display_step == 0:\n",
    "                accuracy = acc.eval({x: x_val, y: y_val, keep_prob: 1.0})\n",
    "                print(\"Epoch: \", '%02d' % (epoch+1), \"  =====> Loss=\", \"{:.9f}\".format(avg_cost))\n",
    "                print(\"Epoch: \", '%02d' % (epoch+1), \"  =====> Validation accuracy=\", \n",
    "                                              \"{:.9f}\".format(accuracy))\n",
    "                \n",
    "                #if accuracy > 0.99:\n",
    "                    #print(\"[EPOCH {0}] Reached validation accuracy > 99% , stopping training\".format(epoch + 1))\n",
    "                    #break\n",
    "\n",
    "        x_test = mnist.test.images.reshape(-1, 28, 28, 1)\n",
    "        y_test = mnist.test.labels\n",
    "        print(\"Accuracy:\", acc.eval({x: x_test, y: y_test, keep_prob: 1.0}))\n",
    "        saver.save(sess, out_dir)\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Training Finished!\")\n",
    "    \n",
    "   #Your implementation for testing accuracy after training goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training!\n",
      "Epoch:  01   =====> Loss= 2.306220544\n",
      "Epoch:  01   =====> Validation accuracy= 0.112599999\n",
      "Epoch:  02   =====> Loss= 2.305765380\n",
      "Epoch:  02   =====> Validation accuracy= 0.112599999\n",
      "Epoch:  03   =====> Loss= 2.304829811\n",
      "Epoch:  03   =====> Validation accuracy= 0.109999999\n",
      "Epoch:  04   =====> Loss= 2.304256634\n",
      "Epoch:  04   =====> Validation accuracy= 0.097599998\n",
      "Epoch:  05   =====> Loss= 2.303919562\n",
      "Epoch:  05   =====> Validation accuracy= 0.112599999\n",
      "Epoch:  06   =====> Loss= 2.303605696\n",
      "Epoch:  06   =====> Validation accuracy= 0.098600000\n",
      "Epoch:  07   =====> Loss= 2.302925382\n",
      "Epoch:  07   =====> Validation accuracy= 0.183400005\n",
      "Epoch:  08   =====> Loss= 2.302268229\n",
      "Epoch:  08   =====> Validation accuracy= 0.097599998\n",
      "Epoch:  09   =====> Loss= 2.300304821\n",
      "Epoch:  09   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  10   =====> Loss= 2.298719998\n",
      "Epoch:  10   =====> Validation accuracy= 0.097599998\n",
      "Epoch:  11   =====> Loss= 2.291144160\n",
      "Epoch:  11   =====> Validation accuracy= 0.115000002\n",
      "Epoch:  12   =====> Loss= 2.226271333\n",
      "Epoch:  12   =====> Validation accuracy= 0.277200013\n",
      "Epoch:  13   =====> Loss= 1.744757301\n",
      "Epoch:  13   =====> Validation accuracy= 0.563199997\n",
      "Epoch:  14   =====> Loss= 1.078477798\n",
      "Epoch:  14   =====> Validation accuracy= 0.773000002\n",
      "Epoch:  15   =====> Loss= 0.666857657\n",
      "Epoch:  15   =====> Validation accuracy= 0.842400014\n",
      "Epoch:  16   =====> Loss= 0.482939510\n",
      "Epoch:  16   =====> Validation accuracy= 0.885599971\n",
      "Epoch:  17   =====> Loss= 0.367552401\n",
      "Epoch:  17   =====> Validation accuracy= 0.910200000\n",
      "Epoch:  18   =====> Loss= 0.299098168\n",
      "Epoch:  18   =====> Validation accuracy= 0.929400027\n",
      "Epoch:  19   =====> Loss= 0.256227993\n",
      "Epoch:  19   =====> Validation accuracy= 0.937799990\n",
      "Epoch:  20   =====> Loss= 0.220164140\n",
      "Epoch:  20   =====> Validation accuracy= 0.947000027\n",
      "Epoch:  21   =====> Loss= 0.197801301\n",
      "Epoch:  21   =====> Validation accuracy= 0.951200008\n",
      "Epoch:  22   =====> Loss= 0.180219753\n",
      "Epoch:  22   =====> Validation accuracy= 0.955399990\n",
      "Epoch:  23   =====> Loss= 0.166407693\n",
      "Epoch:  23   =====> Validation accuracy= 0.958599985\n",
      "Epoch:  24   =====> Loss= 0.150442514\n",
      "Epoch:  24   =====> Validation accuracy= 0.961399972\n",
      "Epoch:  25   =====> Loss= 0.141168586\n",
      "Epoch:  25   =====> Validation accuracy= 0.963800013\n",
      "Epoch:  26   =====> Loss= 0.133696071\n",
      "Epoch:  26   =====> Validation accuracy= 0.966600001\n",
      "Epoch:  27   =====> Loss= 0.124113519\n",
      "Epoch:  27   =====> Validation accuracy= 0.967599988\n",
      "Epoch:  28   =====> Loss= 0.115745605\n",
      "Epoch:  28   =====> Validation accuracy= 0.970200002\n",
      "Epoch:  29   =====> Loss= 0.113322575\n",
      "Epoch:  29   =====> Validation accuracy= 0.973200023\n",
      "Epoch:  30   =====> Loss= 0.107090774\n",
      "Epoch:  30   =====> Validation accuracy= 0.973599970\n",
      "Epoch:  31   =====> Loss= 0.103853245\n",
      "Epoch:  31   =====> Validation accuracy= 0.974799991\n",
      "Epoch:  32   =====> Loss= 0.097332344\n",
      "Epoch:  32   =====> Validation accuracy= 0.974799991\n",
      "Epoch:  33   =====> Loss= 0.096059953\n",
      "Epoch:  33   =====> Validation accuracy= 0.975199997\n",
      "Epoch:  34   =====> Loss= 0.090814681\n",
      "Epoch:  34   =====> Validation accuracy= 0.976599991\n",
      "Epoch:  35   =====> Loss= 0.087953391\n",
      "Epoch:  35   =====> Validation accuracy= 0.975399971\n",
      "Epoch:  36   =====> Loss= 0.085866070\n",
      "Epoch:  36   =====> Validation accuracy= 0.977599978\n",
      "Epoch:  37   =====> Loss= 0.083579603\n",
      "Epoch:  37   =====> Validation accuracy= 0.974799991\n",
      "Epoch:  38   =====> Loss= 0.080132408\n",
      "Epoch:  38   =====> Validation accuracy= 0.978600025\n",
      "Epoch:  39   =====> Loss= 0.078289368\n",
      "Epoch:  39   =====> Validation accuracy= 0.977800012\n",
      "Epoch:  40   =====> Loss= 0.076198342\n",
      "Epoch:  40   =====> Validation accuracy= 0.979600012\n",
      "Epoch:  41   =====> Loss= 0.074365399\n",
      "Epoch:  41   =====> Validation accuracy= 0.979200006\n",
      "Epoch:  42   =====> Loss= 0.071527616\n",
      "Epoch:  42   =====> Validation accuracy= 0.978799999\n",
      "Epoch:  43   =====> Loss= 0.070670097\n",
      "Epoch:  43   =====> Validation accuracy= 0.980199993\n",
      "Epoch:  44   =====> Loss= 0.070367078\n",
      "Epoch:  44   =====> Validation accuracy= 0.978600025\n",
      "Epoch:  45   =====> Loss= 0.066972317\n",
      "Epoch:  45   =====> Validation accuracy= 0.981000006\n",
      "Epoch:  46   =====> Loss= 0.067229749\n",
      "Epoch:  46   =====> Validation accuracy= 0.980400026\n",
      "Epoch:  47   =====> Loss= 0.063354802\n",
      "Epoch:  47   =====> Validation accuracy= 0.980000019\n",
      "Epoch:  48   =====> Loss= 0.065269149\n",
      "Epoch:  48   =====> Validation accuracy= 0.980599999\n",
      "Epoch:  49   =====> Loss= 0.060185211\n",
      "Epoch:  49   =====> Validation accuracy= 0.982200027\n",
      "Epoch:  50   =====> Loss= 0.061864351\n",
      "Epoch:  50   =====> Validation accuracy= 0.981599987\n",
      "Epoch:  51   =====> Loss= 0.059371474\n",
      "Epoch:  51   =====> Validation accuracy= 0.983600020\n",
      "Epoch:  52   =====> Loss= 0.057844711\n",
      "Epoch:  52   =====> Validation accuracy= 0.981599987\n",
      "Epoch:  53   =====> Loss= 0.057644000\n",
      "Epoch:  53   =====> Validation accuracy= 0.982599974\n",
      "Epoch:  54   =====> Loss= 0.058815040\n",
      "Epoch:  54   =====> Validation accuracy= 0.983600020\n",
      "Epoch:  55   =====> Loss= 0.053702723\n",
      "Epoch:  55   =====> Validation accuracy= 0.982599974\n",
      "Epoch:  56   =====> Loss= 0.054988446\n",
      "Epoch:  56   =====> Validation accuracy= 0.983399987\n",
      "Epoch:  57   =====> Loss= 0.053886379\n",
      "Epoch:  57   =====> Validation accuracy= 0.982400000\n",
      "Epoch:  58   =====> Loss= 0.053985186\n",
      "Epoch:  58   =====> Validation accuracy= 0.983799994\n",
      "Epoch:  59   =====> Loss= 0.050431061\n",
      "Epoch:  59   =====> Validation accuracy= 0.983600020\n",
      "Epoch:  60   =====> Loss= 0.051445094\n",
      "Epoch:  60   =====> Validation accuracy= 0.984399974\n",
      "Epoch:  61   =====> Loss= 0.050845009\n",
      "Epoch:  61   =====> Validation accuracy= 0.984000027\n",
      "Epoch:  62   =====> Loss= 0.049181551\n",
      "Epoch:  62   =====> Validation accuracy= 0.984799981\n",
      "Epoch:  63   =====> Loss= 0.048076282\n",
      "Epoch:  63   =====> Validation accuracy= 0.984000027\n",
      "Epoch:  64   =====> Loss= 0.047540146\n",
      "Epoch:  64   =====> Validation accuracy= 0.985199988\n",
      "Epoch:  65   =====> Loss= 0.048447372\n",
      "Epoch:  65   =====> Validation accuracy= 0.984799981\n",
      "Epoch:  66   =====> Loss= 0.047151461\n",
      "Epoch:  66   =====> Validation accuracy= 0.983600020\n",
      "Epoch:  67   =====> Loss= 0.045446167\n",
      "Epoch:  67   =====> Validation accuracy= 0.984200001\n",
      "Epoch:  68   =====> Loss= 0.044895682\n",
      "Epoch:  68   =====> Validation accuracy= 0.983799994\n",
      "Epoch:  69   =====> Loss= 0.044063932\n",
      "Epoch:  69   =====> Validation accuracy= 0.985800028\n",
      "Epoch:  70   =====> Loss= 0.043881306\n",
      "Epoch:  70   =====> Validation accuracy= 0.982999980\n",
      "Epoch:  71   =====> Loss= 0.043319349\n",
      "Epoch:  71   =====> Validation accuracy= 0.985599995\n",
      "Epoch:  72   =====> Loss= 0.043049575\n",
      "Epoch:  72   =====> Validation accuracy= 0.985199988\n",
      "Epoch:  73   =====> Loss= 0.041092731\n",
      "Epoch:  73   =====> Validation accuracy= 0.986800015\n",
      "Epoch:  74   =====> Loss= 0.042121006\n",
      "Epoch:  74   =====> Validation accuracy= 0.985400021\n",
      "Epoch:  75   =====> Loss= 0.040263491\n",
      "Epoch:  75   =====> Validation accuracy= 0.987399995\n",
      "Epoch:  76   =====> Loss= 0.040221350\n",
      "Epoch:  76   =====> Validation accuracy= 0.986400008\n",
      "Epoch:  77   =====> Loss= 0.040009963\n",
      "Epoch:  77   =====> Validation accuracy= 0.986599982\n",
      "Epoch:  78   =====> Loss= 0.039411044\n",
      "Epoch:  78   =====> Validation accuracy= 0.986599982\n",
      "Epoch:  79   =====> Loss= 0.037972750\n",
      "Epoch:  79   =====> Validation accuracy= 0.987200022\n",
      "Epoch:  80   =====> Loss= 0.038369847\n",
      "Epoch:  80   =====> Validation accuracy= 0.986599982\n",
      "Epoch:  81   =====> Loss= 0.038069550\n",
      "Epoch:  81   =====> Validation accuracy= 0.986599982\n",
      "Epoch:  82   =====> Loss= 0.037454600\n",
      "Epoch:  82   =====> Validation accuracy= 0.985800028\n",
      "Epoch:  83   =====> Loss= 0.035237559\n",
      "Epoch:  83   =====> Validation accuracy= 0.986800015\n",
      "Epoch:  84   =====> Loss= 0.036122289\n",
      "Epoch:  84   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  85   =====> Loss= 0.035977604\n",
      "Epoch:  85   =====> Validation accuracy= 0.986599982\n",
      "Epoch:  86   =====> Loss= 0.036177129\n",
      "Epoch:  86   =====> Validation accuracy= 0.986800015\n",
      "Epoch:  87   =====> Loss= 0.035121003\n",
      "Epoch:  87   =====> Validation accuracy= 0.986599982\n",
      "Epoch:  88   =====> Loss= 0.033153823\n",
      "Epoch:  88   =====> Validation accuracy= 0.987200022\n",
      "Epoch:  89   =====> Loss= 0.035195530\n",
      "Epoch:  89   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  90   =====> Loss= 0.033440895\n",
      "Epoch:  90   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  91   =====> Loss= 0.033576028\n",
      "Epoch:  91   =====> Validation accuracy= 0.986400008\n",
      "Epoch:  92   =====> Loss= 0.032602030\n",
      "Epoch:  92   =====> Validation accuracy= 0.986800015\n",
      "Epoch:  93   =====> Loss= 0.032682947\n",
      "Epoch:  93   =====> Validation accuracy= 0.986400008\n",
      "Epoch:  94   =====> Loss= 0.031734167\n",
      "Epoch:  94   =====> Validation accuracy= 0.987200022\n",
      "Epoch:  95   =====> Loss= 0.031197720\n",
      "Epoch:  95   =====> Validation accuracy= 0.986800015\n",
      "Epoch:  96   =====> Loss= 0.031221257\n",
      "Epoch:  96   =====> Validation accuracy= 0.986800015\n",
      "Epoch:  97   =====> Loss= 0.030112738\n",
      "Epoch:  97   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  98   =====> Loss= 0.031013121\n",
      "Epoch:  98   =====> Validation accuracy= 0.987200022\n",
      "Epoch:  99   =====> Loss= 0.030495853\n",
      "Epoch:  99   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  100   =====> Loss= 0.029740665\n",
      "Epoch:  100   =====> Validation accuracy= 0.987399995\n",
      "Accuracy: 0.9871\n",
      "Optimization Finished!\n",
      "Training Finished!\n"
     ]
    }
   ],
   "source": [
    "# trainining with first configuration\n",
    "train('./models/lenet5_sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training!\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shape [-1,28,28,1] has negative dimensions\n\t [[Node: InputData = Placeholder[dtype=DT_FLOAT, shape=[?,28,28,1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'InputData', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-18b67fb40993>\", line 8, in <module>\n    x = tf.placeholder(tf.float32, [None, 28, 28, 1], name='InputData')\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1522, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2021, in _placeholder\n    name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2340, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,28,28,1] has negative dimensions\n\t [[Node: InputData = Placeholder[dtype=DT_FLOAT, shape=[?,28,28,1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1117\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape [-1,28,28,1] has negative dimensions\n\t [[Node: InputData = Placeholder[dtype=DT_FLOAT, shape=[?,28,28,1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-1a3ca115b55e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/lenet5_sgd_relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training duration:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minit_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-716badd4f242>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(out_dir, optimizer, display_step, activation, kp)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 _, c, summary = sess.run([optimizer, cost, merged_summary_op],\n\u001b[0;32m---> 50\u001b[0;31m                                          feed_dict={x: batch_xs, y: batch_ys, keep_prob: kp})\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0;31m# Write logs at every iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_batch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 786\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    787\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 994\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    995\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1129\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1130\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape [-1,28,28,1] has negative dimensions\n\t [[Node: InputData = Placeholder[dtype=DT_FLOAT, shape=[?,28,28,1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'InputData', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-18b67fb40993>\", line 8, in <module>\n    x = tf.placeholder(tf.float32, [None, 28, 28, 1], name='InputData')\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1522, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2021, in _placeholder\n    name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2340, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,28,28,1] has negative dimensions\n\t [[Node: InputData = Placeholder[dtype=DT_FLOAT, shape=[?,28,28,1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# training with AdamOptimizer\n",
    "import time\n",
    "init_time = time.time()\n",
    "train('./models/lenet5_sgd_relu', activation='relu')\n",
    "print('Training duration:', time.time() - init_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# training with AdamOptimizer\n",
    "import time\n",
    "init_time = time.time()\n",
    "train('./models/lenet5_adam_relu', optimizer='AdamOptimizer', activation='relu')\n",
    "print('Training duration:', time.time() - init_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.1.6 </b> : Use tensorBoard to visualise and save the LeNet5 Graph and all learning curves. \n",
    "Save all obtained figures in the folder **\"TP2/MNIST_99_Challenge_Figures\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#  insert your obtained figure here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Part 2 </b> : LeNET 5 Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "<b> Question 2.2.1 </b>  Change the sigmoid function with a Relu :\n",
    "\n",
    "- Retrain your network with SGD and AdamOptimizer and then fill the table above  :\n",
    "\n",
    "\n",
    "| Optimizer            |  Gradient Descent         |AdamOptimizer |\n",
    "| -------------        |: -------------: | ---------:   \n",
    "| Validation Accuracy  |         |    |      \n",
    "| Testing Accuracy     |           |    |       \n",
    "| Training Time        |           |        |  |  \n",
    "\n",
    "\n",
    "- Try with different learning rates for each Optimizer (0.0001 and 0.001 ) and different Batch sizes (50 and 128) for 20000 Epochs. \n",
    "\n",
    "- For each optimizer, plot (on the same curve) the **testing accuracies** function to **(learning rate, batch size)** \n",
    "\n",
    "\n",
    "\n",
    "- Did you reach the 99% accuracy ? What are the optimal parametres that gave you the best results? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001\n",
      "Batch size: 50\n",
      "Start Training!\n",
      "Epoch:  01   =====> Loss= 2.324329930\n",
      "Epoch:  01   =====> Validation accuracy= 0.130400002\n",
      "Epoch:  02   =====> Loss= 2.308605538\n",
      "Epoch:  02   =====> Validation accuracy= 0.155800000\n",
      "Epoch:  03   =====> Loss= 2.297603052\n",
      "Epoch:  03   =====> Validation accuracy= 0.178599998\n",
      "Epoch:  04   =====> Loss= 2.288610613\n",
      "Epoch:  04   =====> Validation accuracy= 0.190200001\n",
      "Epoch:  05   =====> Loss= 2.280258192\n",
      "Epoch:  05   =====> Validation accuracy= 0.206599995\n",
      "Epoch:  06   =====> Loss= 2.271804899\n",
      "Epoch:  06   =====> Validation accuracy= 0.224399999\n",
      "Epoch:  07   =====> Loss= 2.262851090\n",
      "Epoch:  07   =====> Validation accuracy= 0.246600002\n",
      "Epoch:  08   =====> Loss= 2.253006443\n",
      "Epoch:  08   =====> Validation accuracy= 0.273000002\n",
      "Epoch:  09   =====> Loss= 2.241876211\n",
      "Epoch:  09   =====> Validation accuracy= 0.312999994\n",
      "Epoch:  10   =====> Loss= 2.228999188\n",
      "Epoch:  10   =====> Validation accuracy= 0.356200010\n",
      "Epoch:  11   =====> Loss= 2.213786695\n",
      "Epoch:  11   =====> Validation accuracy= 0.391000003\n",
      "Epoch:  12   =====> Loss= 2.195394251\n",
      "Epoch:  12   =====> Validation accuracy= 0.416000009\n",
      "Epoch:  13   =====> Loss= 2.172596242\n",
      "Epoch:  13   =====> Validation accuracy= 0.437400013\n",
      "Epoch:  14   =====> Loss= 2.143800696\n",
      "Epoch:  14   =====> Validation accuracy= 0.452600002\n",
      "Epoch:  15   =====> Loss= 2.107099266\n",
      "Epoch:  15   =====> Validation accuracy= 0.470999986\n",
      "Epoch:  16   =====> Loss= 2.060033204\n",
      "Epoch:  16   =====> Validation accuracy= 0.490999997\n",
      "Epoch:  17   =====> Loss= 1.999478934\n",
      "Epoch:  17   =====> Validation accuracy= 0.510800004\n",
      "Epoch:  18   =====> Loss= 1.921895445\n",
      "Epoch:  18   =====> Validation accuracy= 0.534399986\n",
      "Epoch:  19   =====> Loss= 1.823872695\n",
      "Epoch:  19   =====> Validation accuracy= 0.564999998\n",
      "Epoch:  20   =====> Loss= 1.703788178\n",
      "Epoch:  20   =====> Validation accuracy= 0.599600017\n",
      "Epoch:  21   =====> Loss= 1.563686328\n",
      "Epoch:  21   =====> Validation accuracy= 0.644200027\n",
      "Epoch:  22   =====> Loss= 1.412086199\n",
      "Epoch:  22   =====> Validation accuracy= 0.677200019\n",
      "Epoch:  23   =====> Loss= 1.262054524\n",
      "Epoch:  23   =====> Validation accuracy= 0.707000017\n",
      "Epoch:  24   =====> Loss= 1.124286676\n",
      "Epoch:  24   =====> Validation accuracy= 0.739600003\n",
      "Epoch:  25   =====> Loss= 1.004784401\n",
      "Epoch:  25   =====> Validation accuracy= 0.759599984\n",
      "Epoch:  26   =====> Loss= 0.904806900\n",
      "Epoch:  26   =====> Validation accuracy= 0.779600024\n",
      "Epoch:  27   =====> Loss= 0.822923423\n",
      "Epoch:  27   =====> Validation accuracy= 0.796999991\n",
      "Epoch:  28   =====> Loss= 0.756414918\n",
      "Epoch:  28   =====> Validation accuracy= 0.808799982\n",
      "Epoch:  29   =====> Loss= 0.702281408\n",
      "Epoch:  29   =====> Validation accuracy= 0.818000019\n",
      "Epoch:  30   =====> Loss= 0.658020586\n",
      "Epoch:  30   =====> Validation accuracy= 0.826600015\n",
      "Epoch:  31   =====> Loss= 0.621223476\n",
      "Epoch:  31   =====> Validation accuracy= 0.834999979\n",
      "Epoch:  32   =====> Loss= 0.590497317\n",
      "Epoch:  32   =====> Validation accuracy= 0.842599988\n",
      "Epoch:  33   =====> Loss= 0.564609569\n",
      "Epoch:  33   =====> Validation accuracy= 0.848999977\n",
      "Epoch:  34   =====> Loss= 0.542344029\n",
      "Epoch:  34   =====> Validation accuracy= 0.853999972\n",
      "Epoch:  35   =====> Loss= 0.523129912\n",
      "Epoch:  35   =====> Validation accuracy= 0.857200027\n",
      "Epoch:  36   =====> Loss= 0.506295057\n",
      "Epoch:  36   =====> Validation accuracy= 0.861400008\n",
      "Epoch:  37   =====> Loss= 0.491438567\n",
      "Epoch:  37   =====> Validation accuracy= 0.864799976\n",
      "Epoch:  38   =====> Loss= 0.478077831\n",
      "Epoch:  38   =====> Validation accuracy= 0.868399978\n",
      "Epoch:  39   =====> Loss= 0.466040089\n",
      "Epoch:  39   =====> Validation accuracy= 0.871599972\n",
      "Epoch:  40   =====> Loss= 0.454992484\n",
      "Epoch:  40   =====> Validation accuracy= 0.875199974\n",
      "Epoch:  41   =====> Loss= 0.444935786\n",
      "Epoch:  41   =====> Validation accuracy= 0.878199995\n",
      "Epoch:  42   =====> Loss= 0.435653970\n",
      "Epoch:  42   =====> Validation accuracy= 0.881799996\n",
      "Epoch:  43   =====> Loss= 0.427222850\n",
      "Epoch:  43   =====> Validation accuracy= 0.884199977\n",
      "Epoch:  44   =====> Loss= 0.419171525\n",
      "Epoch:  44   =====> Validation accuracy= 0.885800004\n",
      "Epoch:  45   =====> Loss= 0.411825448\n",
      "Epoch:  45   =====> Validation accuracy= 0.887399971\n",
      "Epoch:  46   =====> Loss= 0.404637236\n",
      "Epoch:  46   =====> Validation accuracy= 0.889599979\n",
      "Epoch:  47   =====> Loss= 0.397980519\n",
      "Epoch:  47   =====> Validation accuracy= 0.890399992\n",
      "Epoch:  48   =====> Loss= 0.391606307\n",
      "Epoch:  48   =====> Validation accuracy= 0.892000020\n",
      "Epoch:  49   =====> Loss= 0.385744560\n",
      "Epoch:  49   =====> Validation accuracy= 0.894400001\n",
      "Epoch:  50   =====> Loss= 0.379922105\n",
      "Epoch:  50   =====> Validation accuracy= 0.895600021\n",
      "Epoch:  51   =====> Loss= 0.374546299\n",
      "Epoch:  51   =====> Validation accuracy= 0.899200022\n",
      "Epoch:  52   =====> Loss= 0.369250639\n",
      "Epoch:  52   =====> Validation accuracy= 0.900200009\n",
      "Epoch:  53   =====> Loss= 0.364290048\n",
      "Epoch:  53   =====> Validation accuracy= 0.902199984\n",
      "Epoch:  54   =====> Loss= 0.359583727\n",
      "Epoch:  54   =====> Validation accuracy= 0.902400017\n",
      "Epoch:  55   =====> Loss= 0.355026030\n",
      "Epoch:  55   =====> Validation accuracy= 0.904799998\n",
      "Epoch:  56   =====> Loss= 0.350573830\n",
      "Epoch:  56   =====> Validation accuracy= 0.905600011\n",
      "Epoch:  57   =====> Loss= 0.346498375\n",
      "Epoch:  57   =====> Validation accuracy= 0.906000018\n",
      "Epoch:  58   =====> Loss= 0.342347214\n",
      "Epoch:  58   =====> Validation accuracy= 0.906199992\n",
      "Epoch:  59   =====> Loss= 0.338347385\n",
      "Epoch:  59   =====> Validation accuracy= 0.907800019\n",
      "Epoch:  60   =====> Loss= 0.334681572\n",
      "Epoch:  60   =====> Validation accuracy= 0.907999992\n",
      "Epoch:  61   =====> Loss= 0.330980587\n",
      "Epoch:  61   =====> Validation accuracy= 0.908399999\n",
      "Epoch:  62   =====> Loss= 0.327327408\n",
      "Epoch:  62   =====> Validation accuracy= 0.910200000\n",
      "Epoch:  63   =====> Loss= 0.324143970\n",
      "Epoch:  63   =====> Validation accuracy= 0.910000026\n",
      "Epoch:  64   =====> Loss= 0.320689703\n",
      "Epoch:  64   =====> Validation accuracy= 0.911599994\n",
      "Epoch:  65   =====> Loss= 0.317519167\n",
      "Epoch:  65   =====> Validation accuracy= 0.912000000\n",
      "Epoch:  66   =====> Loss= 0.314397437\n",
      "Epoch:  66   =====> Validation accuracy= 0.912000000\n",
      "Epoch:  67   =====> Loss= 0.311353018\n",
      "Epoch:  67   =====> Validation accuracy= 0.913999975\n",
      "Epoch:  68   =====> Loss= 0.308370145\n",
      "Epoch:  68   =====> Validation accuracy= 0.916999996\n",
      "Epoch:  69   =====> Loss= 0.305372791\n",
      "Epoch:  69   =====> Validation accuracy= 0.915000021\n",
      "Epoch:  70   =====> Loss= 0.302585396\n",
      "Epoch:  70   =====> Validation accuracy= 0.914399981\n",
      "Epoch:  71   =====> Loss= 0.299813679\n",
      "Epoch:  71   =====> Validation accuracy= 0.916000009\n",
      "Epoch:  72   =====> Loss= 0.297307006\n",
      "Epoch:  72   =====> Validation accuracy= 0.916999996\n",
      "Epoch:  73   =====> Loss= 0.294624511\n",
      "Epoch:  73   =====> Validation accuracy= 0.916999996\n",
      "Epoch:  74   =====> Loss= 0.292154442\n",
      "Epoch:  74   =====> Validation accuracy= 0.918399990\n",
      "Epoch:  75   =====> Loss= 0.289620823\n",
      "Epoch:  75   =====> Validation accuracy= 0.918600023\n",
      "Epoch:  76   =====> Loss= 0.287177890\n",
      "Epoch:  76   =====> Validation accuracy= 0.920599997\n",
      "Epoch:  77   =====> Loss= 0.284917861\n",
      "Epoch:  77   =====> Validation accuracy= 0.920199990\n",
      "Epoch:  78   =====> Loss= 0.282442355\n",
      "Epoch:  78   =====> Validation accuracy= 0.921599984\n",
      "Epoch:  79   =====> Loss= 0.280191296\n",
      "Epoch:  79   =====> Validation accuracy= 0.921400011\n",
      "Epoch:  80   =====> Loss= 0.278047177\n",
      "Epoch:  80   =====> Validation accuracy= 0.922599971\n",
      "Epoch:  81   =====> Loss= 0.275848861\n",
      "Epoch:  81   =====> Validation accuracy= 0.922599971\n",
      "Epoch:  82   =====> Loss= 0.273559986\n",
      "Epoch:  82   =====> Validation accuracy= 0.923600018\n",
      "Epoch:  83   =====> Loss= 0.271573475\n",
      "Epoch:  83   =====> Validation accuracy= 0.922800004\n",
      "Epoch:  84   =====> Loss= 0.269559360\n",
      "Epoch:  84   =====> Validation accuracy= 0.925199986\n",
      "Epoch:  85   =====> Loss= 0.267532734\n",
      "Epoch:  85   =====> Validation accuracy= 0.924799979\n",
      "Epoch:  86   =====> Loss= 0.265470896\n",
      "Epoch:  86   =====> Validation accuracy= 0.924600005\n",
      "Epoch:  87   =====> Loss= 0.263493710\n",
      "Epoch:  87   =====> Validation accuracy= 0.925800025\n",
      "Epoch:  88   =====> Loss= 0.261613912\n",
      "Epoch:  88   =====> Validation accuracy= 0.926199973\n",
      "Epoch:  89   =====> Loss= 0.259772438\n",
      "Epoch:  89   =====> Validation accuracy= 0.926800013\n",
      "Epoch:  90   =====> Loss= 0.257971702\n",
      "Epoch:  90   =====> Validation accuracy= 0.927399993\n",
      "Epoch:  91   =====> Loss= 0.256108874\n",
      "Epoch:  91   =====> Validation accuracy= 0.928200006\n",
      "Epoch:  92   =====> Loss= 0.254373339\n",
      "Epoch:  92   =====> Validation accuracy= 0.929400027\n",
      "Epoch:  93   =====> Loss= 0.252558671\n",
      "Epoch:  93   =====> Validation accuracy= 0.928600013\n",
      "Epoch:  94   =====> Loss= 0.250904196\n",
      "Epoch:  94   =====> Validation accuracy= 0.929000020\n",
      "Epoch:  95   =====> Loss= 0.249226599\n",
      "Epoch:  95   =====> Validation accuracy= 0.929799974\n",
      "Epoch:  96   =====> Loss= 0.247462325\n",
      "Epoch:  96   =====> Validation accuracy= 0.929000020\n",
      "Epoch:  97   =====> Loss= 0.245955473\n",
      "Epoch:  97   =====> Validation accuracy= 0.929799974\n",
      "Epoch:  98   =====> Loss= 0.244364203\n",
      "Epoch:  98   =====> Validation accuracy= 0.929799974\n",
      "Epoch:  99   =====> Loss= 0.242839163\n",
      "Epoch:  99   =====> Validation accuracy= 0.931599975\n",
      "Epoch:  100   =====> Loss= 0.241249814\n",
      "Epoch:  100   =====> Validation accuracy= 0.930599988\n",
      "Accuracy: 0.9337\n",
      "Optimization Finished!\n",
      "Training Finished!\n",
      "Start Training!\n",
      "Epoch:  01   =====> Loss= 0.811801426\n",
      "Epoch:  01   =====> Validation accuracy= 0.928600013\n",
      "Epoch:  02   =====> Loss= 0.218146486\n",
      "Epoch:  02   =====> Validation accuracy= 0.953000009\n",
      "Epoch:  03   =====> Loss= 0.150577474\n",
      "Epoch:  03   =====> Validation accuracy= 0.968200028\n",
      "Epoch:  04   =====> Loss= 0.116385617\n",
      "Epoch:  04   =====> Validation accuracy= 0.972000003\n",
      "Epoch:  05   =====> Loss= 0.097483585\n",
      "Epoch:  05   =====> Validation accuracy= 0.975600004\n",
      "Epoch:  06   =====> Loss= 0.084767943\n",
      "Epoch:  06   =====> Validation accuracy= 0.979200006\n",
      "Epoch:  07   =====> Loss= 0.075377578\n",
      "Epoch:  07   =====> Validation accuracy= 0.981000006\n",
      "Epoch:  08   =====> Loss= 0.068447884\n",
      "Epoch:  08   =====> Validation accuracy= 0.982599974\n",
      "Epoch:  09   =====> Loss= 0.062642868\n",
      "Epoch:  09   =====> Validation accuracy= 0.983799994\n",
      "Epoch:  10   =====> Loss= 0.057318841\n",
      "Epoch:  10   =====> Validation accuracy= 0.985000014\n",
      "Epoch:  11   =====> Loss= 0.053310413\n",
      "Epoch:  11   =====> Validation accuracy= 0.983399987\n",
      "Epoch:  12   =====> Loss= 0.049657288\n",
      "Epoch:  12   =====> Validation accuracy= 0.983399987\n",
      "Epoch:  13   =====> Loss= 0.047183748\n",
      "Epoch:  13   =====> Validation accuracy= 0.984600008\n",
      "Epoch:  14   =====> Loss= 0.043819195\n",
      "Epoch:  14   =====> Validation accuracy= 0.985599995\n",
      "Epoch:  15   =====> Loss= 0.041544879\n",
      "Epoch:  15   =====> Validation accuracy= 0.982599974\n",
      "Epoch:  16   =====> Loss= 0.039632136\n",
      "Epoch:  16   =====> Validation accuracy= 0.985000014\n",
      "Epoch:  17   =====> Loss= 0.037485078\n",
      "Epoch:  17   =====> Validation accuracy= 0.984399974\n",
      "Epoch:  18   =====> Loss= 0.035300391\n",
      "Epoch:  18   =====> Validation accuracy= 0.984000027\n",
      "Epoch:  19   =====> Loss= 0.033636070\n",
      "Epoch:  19   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  20   =====> Loss= 0.031940801\n",
      "Epoch:  20   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  21   =====> Loss= 0.030403056\n",
      "Epoch:  21   =====> Validation accuracy= 0.985000014\n",
      "Epoch:  22   =====> Loss= 0.028688048\n",
      "Epoch:  22   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  23   =====> Loss= 0.026878324\n",
      "Epoch:  23   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  24   =====> Loss= 0.026116429\n",
      "Epoch:  24   =====> Validation accuracy= 0.986400008\n",
      "Epoch:  25   =====> Loss= 0.024268517\n",
      "Epoch:  25   =====> Validation accuracy= 0.987800002\n",
      "Epoch:  26   =====> Loss= 0.023886165\n",
      "Epoch:  26   =====> Validation accuracy= 0.988200009\n",
      "Epoch:  27   =====> Loss= 0.021999616\n",
      "Epoch:  27   =====> Validation accuracy= 0.988600016\n",
      "Epoch:  28   =====> Loss= 0.021110701\n",
      "Epoch:  28   =====> Validation accuracy= 0.986400008\n",
      "Epoch:  29   =====> Loss= 0.019860279\n",
      "Epoch:  29   =====> Validation accuracy= 0.988200009\n",
      "Epoch:  30   =====> Loss= 0.019059979\n",
      "Epoch:  30   =====> Validation accuracy= 0.987999976\n",
      "Epoch:  31   =====> Loss= 0.017818066\n",
      "Epoch:  31   =====> Validation accuracy= 0.987200022\n",
      "Epoch:  32   =====> Loss= 0.016728741\n",
      "Epoch:  32   =====> Validation accuracy= 0.987200022\n",
      "Epoch:  33   =====> Loss= 0.016046222\n",
      "Epoch:  33   =====> Validation accuracy= 0.987999976\n",
      "Epoch:  34   =====> Loss= 0.015147857\n",
      "Epoch:  34   =====> Validation accuracy= 0.985599995\n",
      "Epoch:  35   =====> Loss= 0.015097391\n",
      "Epoch:  35   =====> Validation accuracy= 0.988600016\n",
      "Epoch:  36   =====> Loss= 0.013931297\n",
      "Epoch:  36   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  37   =====> Loss= 0.013142869\n",
      "Epoch:  37   =====> Validation accuracy= 0.988799989\n",
      "Epoch:  38   =====> Loss= 0.012357369\n",
      "Epoch:  38   =====> Validation accuracy= 0.987800002\n",
      "Epoch:  39   =====> Loss= 0.012139900\n",
      "Epoch:  39   =====> Validation accuracy= 0.988200009\n",
      "Epoch:  40   =====> Loss= 0.010902503\n",
      "Epoch:  40   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  41   =====> Loss= 0.011344164\n",
      "Epoch:  41   =====> Validation accuracy= 0.988600016\n",
      "Epoch:  42   =====> Loss= 0.009914057\n",
      "Epoch:  42   =====> Validation accuracy= 0.988200009\n",
      "Epoch:  43   =====> Loss= 0.009809235\n",
      "Epoch:  43   =====> Validation accuracy= 0.989400029\n",
      "Epoch:  44   =====> Loss= 0.009118899\n",
      "Epoch:  44   =====> Validation accuracy= 0.988799989\n",
      "Epoch:  45   =====> Loss= 0.009035114\n",
      "Epoch:  45   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  46   =====> Loss= 0.008245570\n",
      "Epoch:  46   =====> Validation accuracy= 0.989600003\n",
      "Epoch:  47   =====> Loss= 0.007362291\n",
      "Epoch:  47   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  48   =====> Loss= 0.007390097\n",
      "Epoch:  48   =====> Validation accuracy= 0.989799976\n",
      "Epoch:  49   =====> Loss= 0.006560783\n",
      "Epoch:  49   =====> Validation accuracy= 0.989000022\n",
      "Epoch:  50   =====> Loss= 0.006877969\n",
      "Epoch:  50   =====> Validation accuracy= 0.989600003\n",
      "Epoch:  51   =====> Loss= 0.006513970\n",
      "Epoch:  51   =====> Validation accuracy= 0.988600016\n",
      "Epoch:  52   =====> Loss= 0.006259621\n",
      "Epoch:  52   =====> Validation accuracy= 0.989400029\n",
      "Epoch:  53   =====> Loss= nan\n",
      "Epoch:  53   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  54   =====> Loss= nan\n",
      "Epoch:  54   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  55   =====> Loss= nan\n",
      "Epoch:  55   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  56   =====> Loss= nan\n",
      "Epoch:  56   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  57   =====> Loss= nan\n",
      "Epoch:  57   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  58   =====> Loss= nan\n",
      "Epoch:  58   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  59   =====> Loss= nan\n",
      "Epoch:  59   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  60   =====> Loss= nan\n",
      "Epoch:  60   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  61   =====> Loss= nan\n",
      "Epoch:  61   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  62   =====> Loss= nan\n",
      "Epoch:  62   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  63   =====> Loss= nan\n",
      "Epoch:  63   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  64   =====> Loss= nan\n",
      "Epoch:  64   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  65   =====> Loss= nan\n",
      "Epoch:  65   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  66   =====> Loss= nan\n",
      "Epoch:  66   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  67   =====> Loss= nan\n",
      "Epoch:  67   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  68   =====> Loss= nan\n",
      "Epoch:  68   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  69   =====> Loss= nan\n",
      "Epoch:  69   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  70   =====> Loss= nan\n",
      "Epoch:  70   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  71   =====> Loss= nan\n",
      "Epoch:  71   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  72   =====> Loss= nan\n",
      "Epoch:  72   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  73   =====> Loss= nan\n",
      "Epoch:  73   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  74   =====> Loss= nan\n",
      "Epoch:  74   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  75   =====> Loss= nan\n",
      "Epoch:  75   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  76   =====> Loss= nan\n",
      "Epoch:  76   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  77   =====> Loss= nan\n",
      "Epoch:  77   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  78   =====> Loss= nan\n",
      "Epoch:  78   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  79   =====> Loss= nan\n",
      "Epoch:  79   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  80   =====> Loss= nan\n",
      "Epoch:  80   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  81   =====> Loss= nan\n",
      "Epoch:  81   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  82   =====> Loss= nan\n",
      "Epoch:  82   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  83   =====> Loss= nan\n",
      "Epoch:  83   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  84   =====> Loss= nan\n",
      "Epoch:  84   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  85   =====> Loss= nan\n",
      "Epoch:  85   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  86   =====> Loss= nan\n",
      "Epoch:  86   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  87   =====> Loss= nan\n",
      "Epoch:  87   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  88   =====> Loss= nan\n",
      "Epoch:  88   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  89   =====> Loss= nan\n",
      "Epoch:  89   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  90   =====> Loss= nan\n",
      "Epoch:  90   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  91   =====> Loss= nan\n",
      "Epoch:  91   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  92   =====> Loss= nan\n",
      "Epoch:  92   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  93   =====> Loss= nan\n",
      "Epoch:  93   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  94   =====> Loss= nan\n",
      "Epoch:  94   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  95   =====> Loss= nan\n",
      "Epoch:  95   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  96   =====> Loss= nan\n",
      "Epoch:  96   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  97   =====> Loss= nan\n",
      "Epoch:  97   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  98   =====> Loss= nan\n",
      "Epoch:  98   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  99   =====> Loss= nan\n",
      "Epoch:  99   =====> Validation accuracy= 0.095799997\n",
      "Epoch:  100   =====> Loss= nan\n",
      "Epoch:  100   =====> Validation accuracy= 0.095799997\n",
      "Accuracy: 0.098\n",
      "Optimization Finished!\n",
      "Training Finished!\n",
      "Batch size: 128\n",
      "Start Training!\n",
      "Epoch:  01   =====> Loss= 2.313704650\n",
      "Epoch:  01   =====> Validation accuracy= 0.167799994\n",
      "Epoch:  02   =====> Loss= 2.304917534\n",
      "Epoch:  02   =====> Validation accuracy= 0.174400002\n",
      "Epoch:  03   =====> Loss= 2.297827315\n",
      "Epoch:  03   =====> Validation accuracy= 0.181799993\n",
      "Epoch:  04   =====> Loss= 2.291545956\n",
      "Epoch:  04   =====> Validation accuracy= 0.185399994\n",
      "Epoch:  05   =====> Loss= 2.286296212\n",
      "Epoch:  05   =====> Validation accuracy= 0.187800005\n",
      "Epoch:  06   =====> Loss= 2.281417763\n",
      "Epoch:  06   =====> Validation accuracy= 0.192000002\n",
      "Epoch:  07   =====> Loss= 2.276728441\n",
      "Epoch:  07   =====> Validation accuracy= 0.197400004\n",
      "Epoch:  08   =====> Loss= 2.272263795\n",
      "Epoch:  08   =====> Validation accuracy= 0.202000007\n",
      "Epoch:  09   =====> Loss= 2.267803147\n",
      "Epoch:  09   =====> Validation accuracy= 0.212799996\n",
      "Epoch:  10   =====> Loss= 2.263435423\n",
      "Epoch:  10   =====> Validation accuracy= 0.226400003\n",
      "Epoch:  11   =====> Loss= 2.259068802\n",
      "Epoch:  11   =====> Validation accuracy= 0.237399995\n",
      "Epoch:  12   =====> Loss= 2.254878198\n",
      "Epoch:  12   =====> Validation accuracy= 0.254799992\n",
      "Epoch:  13   =====> Loss= 2.250356171\n",
      "Epoch:  13   =====> Validation accuracy= 0.271200001\n",
      "Epoch:  14   =====> Loss= 2.245853092\n",
      "Epoch:  14   =====> Validation accuracy= 0.284200013\n",
      "Epoch:  15   =====> Loss= 2.241623568\n",
      "Epoch:  15   =====> Validation accuracy= 0.302399993\n",
      "Epoch:  16   =====> Loss= 2.236801510\n",
      "Epoch:  16   =====> Validation accuracy= 0.319799989\n",
      "Epoch:  17   =====> Loss= 2.232160169\n",
      "Epoch:  17   =====> Validation accuracy= 0.333000004\n",
      "Epoch:  18   =====> Loss= 2.227049502\n",
      "Epoch:  18   =====> Validation accuracy= 0.347600013\n",
      "Epoch:  19   =====> Loss= 2.221816335\n",
      "Epoch:  19   =====> Validation accuracy= 0.362599999\n",
      "Epoch:  20   =====> Loss= 2.216285712\n",
      "Epoch:  20   =====> Validation accuracy= 0.378600001\n",
      "Epoch:  21   =====> Loss= 2.210427931\n",
      "Epoch:  21   =====> Validation accuracy= 0.397000015\n",
      "Epoch:  22   =====> Loss= 2.204389620\n",
      "Epoch:  22   =====> Validation accuracy= 0.418799996\n",
      "Epoch:  23   =====> Loss= 2.197727942\n",
      "Epoch:  23   =====> Validation accuracy= 0.440800011\n",
      "Epoch:  24   =====> Loss= 2.190643723\n",
      "Epoch:  24   =====> Validation accuracy= 0.462599993\n",
      "Epoch:  25   =====> Loss= 2.183135422\n",
      "Epoch:  25   =====> Validation accuracy= 0.482400000\n",
      "Epoch:  26   =====> Loss= 2.175045676\n",
      "Epoch:  26   =====> Validation accuracy= 0.504400015\n",
      "Epoch:  27   =====> Loss= 2.166547839\n",
      "Epoch:  27   =====> Validation accuracy= 0.520799994\n",
      "Epoch:  28   =====> Loss= 2.156864246\n",
      "Epoch:  28   =====> Validation accuracy= 0.533999979\n",
      "Epoch:  29   =====> Loss= 2.146807225\n",
      "Epoch:  29   =====> Validation accuracy= 0.550000012\n",
      "Epoch:  30   =====> Loss= 2.135811384\n",
      "Epoch:  30   =====> Validation accuracy= 0.561600029\n",
      "Epoch:  31   =====> Loss= 2.123822296\n",
      "Epoch:  31   =====> Validation accuracy= 0.574199975\n",
      "Epoch:  32   =====> Loss= 2.110773176\n",
      "Epoch:  32   =====> Validation accuracy= 0.588999987\n",
      "Epoch:  33   =====> Loss= 2.096099571\n",
      "Epoch:  33   =====> Validation accuracy= 0.605599999\n",
      "Epoch:  34   =====> Loss= 2.080317620\n",
      "Epoch:  34   =====> Validation accuracy= 0.616999984\n",
      "Epoch:  35   =====> Loss= 2.063077573\n",
      "Epoch:  35   =====> Validation accuracy= 0.628799975\n",
      "Epoch:  36   =====> Loss= 2.044409517\n",
      "Epoch:  36   =====> Validation accuracy= 0.639999986\n",
      "Epoch:  37   =====> Loss= 2.023017829\n",
      "Epoch:  37   =====> Validation accuracy= 0.649399996\n",
      "Epoch:  38   =====> Loss= 2.000459633\n",
      "Epoch:  38   =====> Validation accuracy= 0.659600019\n",
      "Epoch:  39   =====> Loss= 1.974736511\n",
      "Epoch:  39   =====> Validation accuracy= 0.674799979\n",
      "Epoch:  40   =====> Loss= 1.947710638\n",
      "Epoch:  40   =====> Validation accuracy= 0.681800008\n",
      "Epoch:  41   =====> Loss= 1.916538749\n",
      "Epoch:  41   =====> Validation accuracy= 0.685400009\n",
      "Epoch:  42   =====> Loss= 1.883558192\n",
      "Epoch:  42   =====> Validation accuracy= 0.692399979\n",
      "Epoch:  43   =====> Loss= 1.846108458\n",
      "Epoch:  43   =====> Validation accuracy= 0.699800014\n",
      "Epoch:  44   =====> Loss= 1.807376124\n",
      "Epoch:  44   =====> Validation accuracy= 0.707599998\n",
      "Epoch:  45   =====> Loss= 1.765283298\n",
      "Epoch:  45   =====> Validation accuracy= 0.718400002\n",
      "Epoch:  46   =====> Loss= 1.717812893\n",
      "Epoch:  46   =====> Validation accuracy= 0.728399992\n",
      "Epoch:  47   =====> Loss= 1.669140244\n",
      "Epoch:  47   =====> Validation accuracy= 0.730199993\n",
      "Epoch:  48   =====> Loss= 1.616046268\n",
      "Epoch:  48   =====> Validation accuracy= 0.743399978\n",
      "Epoch:  49   =====> Loss= 1.562166903\n",
      "Epoch:  49   =====> Validation accuracy= 0.749800026\n",
      "Epoch:  50   =====> Loss= 1.503941491\n",
      "Epoch:  50   =====> Validation accuracy= 0.756200016\n",
      "Epoch:  51   =====> Loss= 1.446654131\n",
      "Epoch:  51   =====> Validation accuracy= 0.764999986\n",
      "Epoch:  52   =====> Loss= 1.386770919\n",
      "Epoch:  52   =====> Validation accuracy= 0.773000002\n",
      "Epoch:  53   =====> Loss= 1.328177119\n",
      "Epoch:  53   =====> Validation accuracy= 0.779999971\n",
      "Epoch:  54   =====> Loss= 1.267744845\n",
      "Epoch:  54   =====> Validation accuracy= 0.785600007\n",
      "Epoch:  55   =====> Loss= 1.213721353\n",
      "Epoch:  55   =====> Validation accuracy= 0.789399981\n",
      "Epoch:  56   =====> Loss= 1.154097843\n",
      "Epoch:  56   =====> Validation accuracy= 0.794200003\n",
      "Epoch:  57   =====> Loss= 1.105481584\n",
      "Epoch:  57   =====> Validation accuracy= 0.798799992\n",
      "Epoch:  58   =====> Loss= 1.050856362\n",
      "Epoch:  58   =====> Validation accuracy= 0.801800013\n",
      "Epoch:  59   =====> Loss= 1.003355509\n",
      "Epoch:  59   =====> Validation accuracy= 0.805599988\n",
      "Epoch:  60   =====> Loss= 0.959852547\n",
      "Epoch:  60   =====> Validation accuracy= 0.808600008\n",
      "Epoch:  61   =====> Loss= 0.915465041\n",
      "Epoch:  61   =====> Validation accuracy= 0.813199997\n",
      "Epoch:  62   =====> Loss= 0.879323607\n",
      "Epoch:  62   =====> Validation accuracy= 0.816999972\n",
      "Epoch:  63   =====> Loss= 0.844151843\n",
      "Epoch:  63   =====> Validation accuracy= 0.820599973\n",
      "Epoch:  64   =====> Loss= 0.807696406\n",
      "Epoch:  64   =====> Validation accuracy= 0.822799981\n",
      "Epoch:  65   =====> Loss= 0.781487190\n",
      "Epoch:  65   =====> Validation accuracy= 0.827799976\n",
      "Epoch:  66   =====> Loss= 0.751292334\n",
      "Epoch:  66   =====> Validation accuracy= 0.830399990\n",
      "Epoch:  67   =====> Loss= 0.727468218\n",
      "Epoch:  67   =====> Validation accuracy= 0.834800005\n",
      "Epoch:  68   =====> Loss= 0.705805849\n",
      "Epoch:  68   =====> Validation accuracy= 0.838800013\n",
      "Epoch:  69   =====> Loss= 0.680942417\n",
      "Epoch:  69   =====> Validation accuracy= 0.839600027\n",
      "Epoch:  70   =====> Loss= 0.663968721\n",
      "Epoch:  70   =====> Validation accuracy= 0.843599975\n",
      "Epoch:  71   =====> Loss= 0.645042033\n",
      "Epoch:  71   =====> Validation accuracy= 0.847400010\n",
      "Epoch:  72   =====> Loss= 0.629568370\n",
      "Epoch:  72   =====> Validation accuracy= 0.850799978\n",
      "Epoch:  73   =====> Loss= 0.611407330\n",
      "Epoch:  73   =====> Validation accuracy= 0.851999998\n",
      "Epoch:  74   =====> Loss= 0.601009363\n",
      "Epoch:  74   =====> Validation accuracy= 0.853999972\n",
      "Epoch:  75   =====> Loss= 0.583235388\n",
      "Epoch:  75   =====> Validation accuracy= 0.855799973\n",
      "Epoch:  76   =====> Loss= 0.573400505\n",
      "Epoch:  76   =====> Validation accuracy= 0.857200027\n",
      "Epoch:  77   =====> Loss= 0.558426078\n",
      "Epoch:  77   =====> Validation accuracy= 0.857800007\n",
      "Epoch:  78   =====> Loss= 0.552091725\n",
      "Epoch:  78   =====> Validation accuracy= 0.860199988\n",
      "Epoch:  79   =====> Loss= 0.535706869\n",
      "Epoch:  79   =====> Validation accuracy= 0.861999989\n",
      "Epoch:  80   =====> Loss= 0.531309517\n",
      "Epoch:  80   =====> Validation accuracy= 0.864199996\n",
      "Epoch:  81   =====> Loss= 0.520964359\n",
      "Epoch:  81   =====> Validation accuracy= 0.864799976\n",
      "Epoch:  82   =====> Loss= 0.511230814\n",
      "Epoch:  82   =====> Validation accuracy= 0.867799997\n",
      "Epoch:  83   =====> Loss= 0.502187346\n",
      "Epoch:  83   =====> Validation accuracy= 0.867600024\n",
      "Epoch:  84   =====> Loss= 0.495985744\n",
      "Epoch:  84   =====> Validation accuracy= 0.869799972\n",
      "Epoch:  85   =====> Loss= 0.488005186\n",
      "Epoch:  85   =====> Validation accuracy= 0.871800005\n",
      "Epoch:  86   =====> Loss= 0.481014139\n",
      "Epoch:  86   =====> Validation accuracy= 0.872200012\n",
      "Epoch:  87   =====> Loss= 0.475071618\n",
      "Epoch:  87   =====> Validation accuracy= 0.873799980\n",
      "Epoch:  88   =====> Loss= 0.465261790\n",
      "Epoch:  88   =====> Validation accuracy= 0.876600027\n",
      "Epoch:  89   =====> Loss= 0.462657899\n",
      "Epoch:  89   =====> Validation accuracy= 0.876399994\n",
      "Epoch:  90   =====> Loss= 0.456287765\n",
      "Epoch:  90   =====> Validation accuracy= 0.878799975\n",
      "Epoch:  91   =====> Loss= 0.450444937\n",
      "Epoch:  91   =====> Validation accuracy= 0.879400015\n",
      "Epoch:  92   =====> Loss= 0.443574061\n",
      "Epoch:  92   =====> Validation accuracy= 0.881399989\n",
      "Epoch:  93   =====> Loss= 0.438806078\n",
      "Epoch:  93   =====> Validation accuracy= 0.881799996\n",
      "Epoch:  94   =====> Loss= 0.434961130\n",
      "Epoch:  94   =====> Validation accuracy= 0.884400010\n",
      "Epoch:  95   =====> Loss= 0.430010512\n",
      "Epoch:  95   =====> Validation accuracy= 0.884999990\n",
      "Epoch:  96   =====> Loss= 0.421623618\n",
      "Epoch:  96   =====> Validation accuracy= 0.887399971\n",
      "Epoch:  97   =====> Loss= 0.424887544\n",
      "Epoch:  97   =====> Validation accuracy= 0.886600018\n",
      "Epoch:  98   =====> Loss= 0.412372186\n",
      "Epoch:  98   =====> Validation accuracy= 0.888800025\n",
      "Epoch:  99   =====> Loss= 0.413520426\n",
      "Epoch:  99   =====> Validation accuracy= 0.888599992\n",
      "Epoch:  100   =====> Loss= 0.407966820\n",
      "Epoch:  100   =====> Validation accuracy= 0.890399992\n",
      "Accuracy: 0.8948\n",
      "Optimization Finished!\n",
      "Training Finished!\n",
      "Start Training!\n",
      "Epoch:  01   =====> Loss= 1.192594243\n",
      "Epoch:  01   =====> Validation accuracy= 0.893999994\n",
      "Epoch:  02   =====> Loss= 0.323779055\n",
      "Epoch:  02   =====> Validation accuracy= 0.927399993\n",
      "Epoch:  03   =====> Loss= 0.235962131\n",
      "Epoch:  03   =====> Validation accuracy= 0.944999993\n",
      "Epoch:  04   =====> Loss= 0.191672827\n",
      "Epoch:  04   =====> Validation accuracy= 0.957599998\n",
      "Epoch:  05   =====> Loss= 0.158238585\n",
      "Epoch:  05   =====> Validation accuracy= 0.961799979\n",
      "Epoch:  06   =====> Loss= 0.136974041\n",
      "Epoch:  06   =====> Validation accuracy= 0.967800021\n",
      "Epoch:  07   =====> Loss= 0.118838912\n",
      "Epoch:  07   =====> Validation accuracy= 0.970799983\n",
      "Epoch:  08   =====> Loss= 0.106086160\n",
      "Epoch:  08   =====> Validation accuracy= 0.971000016\n",
      "Epoch:  09   =====> Loss= 0.095657594\n",
      "Epoch:  09   =====> Validation accuracy= 0.973399997\n",
      "Epoch:  10   =====> Loss= 0.089536132\n",
      "Epoch:  10   =====> Validation accuracy= 0.977599978\n",
      "Epoch:  11   =====> Loss= 0.081611707\n",
      "Epoch:  11   =====> Validation accuracy= 0.978799999\n",
      "Epoch:  12   =====> Loss= 0.077091948\n",
      "Epoch:  12   =====> Validation accuracy= 0.980599999\n",
      "Epoch:  13   =====> Loss= 0.070838214\n",
      "Epoch:  13   =====> Validation accuracy= 0.980000019\n",
      "Epoch:  14   =====> Loss= 0.066908935\n",
      "Epoch:  14   =====> Validation accuracy= 0.980799973\n",
      "Epoch:  15   =====> Loss= 0.062759942\n",
      "Epoch:  15   =====> Validation accuracy= 0.981000006\n",
      "Epoch:  16   =====> Loss= 0.059633226\n",
      "Epoch:  16   =====> Validation accuracy= 0.982599974\n",
      "Epoch:  17   =====> Loss= 0.057695165\n",
      "Epoch:  17   =====> Validation accuracy= 0.984000027\n",
      "Epoch:  18   =====> Loss= 0.054108919\n",
      "Epoch:  18   =====> Validation accuracy= 0.982599974\n",
      "Epoch:  19   =====> Loss= 0.052512262\n",
      "Epoch:  19   =====> Validation accuracy= 0.984200001\n",
      "Epoch:  20   =====> Loss= 0.049949096\n",
      "Epoch:  20   =====> Validation accuracy= 0.983799994\n",
      "Epoch:  21   =====> Loss= 0.046791589\n",
      "Epoch:  21   =====> Validation accuracy= 0.984399974\n",
      "Epoch:  22   =====> Loss= 0.045546927\n",
      "Epoch:  22   =====> Validation accuracy= 0.983399987\n",
      "Epoch:  23   =====> Loss= 0.042336016\n",
      "Epoch:  23   =====> Validation accuracy= 0.984200001\n",
      "Epoch:  24   =====> Loss= 0.042858638\n",
      "Epoch:  24   =====> Validation accuracy= 0.986199975\n",
      "Epoch:  25   =====> Loss= 0.040717982\n",
      "Epoch:  25   =====> Validation accuracy= 0.985400021\n",
      "Epoch:  26   =====> Loss= 0.039816257\n",
      "Epoch:  26   =====> Validation accuracy= 0.985400021\n",
      "Epoch:  27   =====> Loss= 0.036228903\n",
      "Epoch:  27   =====> Validation accuracy= 0.985599995\n",
      "Epoch:  28   =====> Loss= 0.037251111\n",
      "Epoch:  28   =====> Validation accuracy= 0.987399995\n",
      "Epoch:  29   =====> Loss= 0.036346175\n",
      "Epoch:  29   =====> Validation accuracy= 0.983399987\n",
      "Epoch:  30   =====> Loss= 0.034031558\n",
      "Epoch:  30   =====> Validation accuracy= 0.985000014\n",
      "Epoch:  31   =====> Loss= 0.032988787\n",
      "Epoch:  31   =====> Validation accuracy= 0.985800028\n",
      "Epoch:  32   =====> Loss= 0.031969774\n",
      "Epoch:  32   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  33   =====> Loss= 0.031667045\n",
      "Epoch:  33   =====> Validation accuracy= 0.988399982\n",
      "Epoch:  34   =====> Loss= 0.029456899\n",
      "Epoch:  34   =====> Validation accuracy= 0.987600029\n",
      "Epoch:  35   =====> Loss= 0.029530474\n",
      "Epoch:  35   =====> Validation accuracy= 0.988399982\n",
      "Epoch:  36   =====> Loss= 0.027506605\n",
      "Epoch:  36   =====> Validation accuracy= 0.988399982\n",
      "Epoch:  37   =====> Loss= 0.027918144\n",
      "Epoch:  37   =====> Validation accuracy= 0.987600029\n",
      "Epoch:  38   =====> Loss= 0.026047738\n",
      "Epoch:  38   =====> Validation accuracy= 0.987600029\n",
      "Epoch:  39   =====> Loss= 0.024839453\n",
      "Epoch:  39   =====> Validation accuracy= 0.987800002\n",
      "Epoch:  40   =====> Loss= 0.024384591\n",
      "Epoch:  40   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  41   =====> Loss= 0.025164030\n",
      "Epoch:  41   =====> Validation accuracy= 0.988799989\n",
      "Epoch:  42   =====> Loss= 0.023823285\n",
      "Epoch:  42   =====> Validation accuracy= 0.987800002\n",
      "Epoch:  43   =====> Loss= 0.022526917\n",
      "Epoch:  43   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  44   =====> Loss= 0.021319224\n",
      "Epoch:  44   =====> Validation accuracy= 0.987600029\n",
      "Epoch:  45   =====> Loss= 0.020253769\n",
      "Epoch:  45   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  46   =====> Loss= 0.022277386\n",
      "Epoch:  46   =====> Validation accuracy= 0.988200009\n",
      "Epoch:  47   =====> Loss= 0.018595788\n",
      "Epoch:  47   =====> Validation accuracy= 0.989000022\n",
      "Epoch:  48   =====> Loss= 0.018487111\n",
      "Epoch:  48   =====> Validation accuracy= 0.987600029\n",
      "Epoch:  49   =====> Loss= 0.020097199\n",
      "Epoch:  49   =====> Validation accuracy= 0.989799976\n",
      "Epoch:  50   =====> Loss= 0.017127425\n",
      "Epoch:  50   =====> Validation accuracy= 0.987200022\n",
      "Epoch:  51   =====> Loss= 0.017614071\n",
      "Epoch:  51   =====> Validation accuracy= 0.988399982\n",
      "Epoch:  52   =====> Loss= 0.017417424\n",
      "Epoch:  52   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  53   =====> Loss= 0.016279133\n",
      "Epoch:  53   =====> Validation accuracy= 0.987800002\n",
      "Epoch:  54   =====> Loss= 0.015305572\n",
      "Epoch:  54   =====> Validation accuracy= 0.989000022\n",
      "Epoch:  55   =====> Loss= 0.015921375\n",
      "Epoch:  55   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  56   =====> Loss= 0.014808582\n",
      "Epoch:  56   =====> Validation accuracy= 0.989000022\n",
      "Epoch:  57   =====> Loss= 0.014282897\n",
      "Epoch:  57   =====> Validation accuracy= 0.989799976\n",
      "Epoch:  58   =====> Loss= 0.013539717\n",
      "Epoch:  58   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  59   =====> Loss= 0.014619049\n",
      "Epoch:  59   =====> Validation accuracy= 0.988399982\n",
      "Epoch:  60   =====> Loss= 0.012837926\n",
      "Epoch:  60   =====> Validation accuracy= 0.989799976\n",
      "Epoch:  61   =====> Loss= 0.013170191\n",
      "Epoch:  61   =====> Validation accuracy= 0.989799976\n",
      "Epoch:  62   =====> Loss= 0.012156300\n",
      "Epoch:  62   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  63   =====> Loss= 0.011899919\n",
      "Epoch:  63   =====> Validation accuracy= 0.989000022\n",
      "Epoch:  64   =====> Loss= 0.012430809\n",
      "Epoch:  64   =====> Validation accuracy= 0.989400029\n",
      "Epoch:  65   =====> Loss= 0.011771070\n",
      "Epoch:  65   =====> Validation accuracy= 0.988399982\n",
      "Epoch:  66   =====> Loss= 0.010399778\n",
      "Epoch:  66   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  67   =====> Loss= 0.011178867\n",
      "Epoch:  67   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  68   =====> Loss= 0.009867517\n",
      "Epoch:  68   =====> Validation accuracy= 0.989600003\n",
      "Epoch:  69   =====> Loss= 0.009603621\n",
      "Epoch:  69   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  70   =====> Loss= 0.009940697\n",
      "Epoch:  70   =====> Validation accuracy= 0.990000010\n",
      "[EPOCH 70] Reached validation accuracy > 99% , stopping training\n",
      "Accuracy: 0.9899\n",
      "Optimization Finished!\n",
      "Training Finished!\n",
      "Learning rate: 0.001\n",
      "Batch size: 50\n",
      "Start Training!\n",
      "Epoch:  01   =====> Loss= 2.171414877\n",
      "Epoch:  01   =====> Validation accuracy= 0.618200004\n",
      "Epoch:  02   =====> Loss= 1.275223136\n",
      "Epoch:  02   =====> Validation accuracy= 0.811600029\n",
      "Epoch:  03   =====> Loss= 0.561046971\n",
      "Epoch:  03   =====> Validation accuracy= 0.871800005\n",
      "Epoch:  04   =====> Loss= 0.412670510\n",
      "Epoch:  04   =====> Validation accuracy= 0.892799973\n",
      "Epoch:  05   =====> Loss= 0.348483989\n",
      "Epoch:  05   =====> Validation accuracy= 0.908599973\n",
      "Epoch:  06   =====> Loss= 0.308520240\n",
      "Epoch:  06   =====> Validation accuracy= 0.914399981\n",
      "Epoch:  07   =====> Loss= 0.280215439\n",
      "Epoch:  07   =====> Validation accuracy= 0.922200024\n",
      "Epoch:  08   =====> Loss= 0.259116445\n",
      "Epoch:  08   =====> Validation accuracy= 0.928799987\n",
      "Epoch:  09   =====> Loss= 0.236870373\n",
      "Epoch:  09   =====> Validation accuracy= 0.933799982\n",
      "Epoch:  10   =====> Loss= 0.231088578\n",
      "Epoch:  10   =====> Validation accuracy= 0.938600004\n",
      "Epoch:  11   =====> Loss= 0.208883791\n",
      "Epoch:  11   =====> Validation accuracy= 0.941999972\n",
      "Epoch:  12   =====> Loss= 0.202476030\n",
      "Epoch:  12   =====> Validation accuracy= 0.944999993\n",
      "Epoch:  13   =====> Loss= 0.189221632\n",
      "Epoch:  13   =====> Validation accuracy= 0.950200021\n",
      "Epoch:  14   =====> Loss= 0.177741872\n",
      "Epoch:  14   =====> Validation accuracy= 0.951200008\n",
      "Epoch:  15   =====> Loss= 0.173621605\n",
      "Epoch:  15   =====> Validation accuracy= 0.953800023\n",
      "Epoch:  16   =====> Loss= 0.164635335\n",
      "Epoch:  16   =====> Validation accuracy= 0.954400003\n",
      "Epoch:  17   =====> Loss= 0.156385041\n",
      "Epoch:  17   =====> Validation accuracy= 0.956600010\n",
      "Epoch:  18   =====> Loss= 0.152749479\n",
      "Epoch:  18   =====> Validation accuracy= 0.961399972\n",
      "Epoch:  19   =====> Loss= 0.146830300\n",
      "Epoch:  19   =====> Validation accuracy= 0.959399998\n",
      "Epoch:  20   =====> Loss= 0.140501867\n",
      "Epoch:  20   =====> Validation accuracy= 0.962800026\n",
      "Epoch:  21   =====> Loss= 0.136606235\n",
      "Epoch:  21   =====> Validation accuracy= 0.964600027\n",
      "Epoch:  22   =====> Loss= 0.131946137\n",
      "Epoch:  22   =====> Validation accuracy= 0.964600027\n",
      "Epoch:  23   =====> Loss= 0.127380476\n",
      "Epoch:  23   =====> Validation accuracy= 0.964999974\n",
      "Epoch:  24   =====> Loss= 0.122158735\n",
      "Epoch:  24   =====> Validation accuracy= 0.966600001\n",
      "Epoch:  25   =====> Loss= 0.120069464\n",
      "Epoch:  25   =====> Validation accuracy= 0.965799987\n",
      "Epoch:  26   =====> Loss= 0.117219983\n",
      "Epoch:  26   =====> Validation accuracy= 0.969399989\n",
      "Epoch:  27   =====> Loss= 0.111996602\n",
      "Epoch:  27   =====> Validation accuracy= 0.969799995\n",
      "Epoch:  28   =====> Loss= 0.112104757\n",
      "Epoch:  28   =====> Validation accuracy= 0.969799995\n",
      "Epoch:  29   =====> Loss= 0.106735355\n",
      "Epoch:  29   =====> Validation accuracy= 0.972199976\n",
      "Epoch:  30   =====> Loss= 0.105882067\n",
      "Epoch:  30   =====> Validation accuracy= 0.970600009\n",
      "Epoch:  31   =====> Loss= 0.101960639\n",
      "Epoch:  31   =====> Validation accuracy= 0.972800016\n",
      "Epoch:  32   =====> Loss= 0.103198781\n",
      "Epoch:  32   =====> Validation accuracy= 0.971599996\n",
      "Epoch:  33   =====> Loss= 0.097598062\n",
      "Epoch:  33   =====> Validation accuracy= 0.972800016\n",
      "Epoch:  34   =====> Loss= 0.096838421\n",
      "Epoch:  34   =====> Validation accuracy= 0.974399984\n",
      "Epoch:  35   =====> Loss= 0.094508331\n",
      "Epoch:  35   =====> Validation accuracy= 0.974200010\n",
      "Epoch:  36   =====> Loss= 0.091161577\n",
      "Epoch:  36   =====> Validation accuracy= 0.973999977\n",
      "Epoch:  37   =====> Loss= 0.090992061\n",
      "Epoch:  37   =====> Validation accuracy= 0.974799991\n",
      "Epoch:  38   =====> Loss= 0.090286463\n",
      "Epoch:  38   =====> Validation accuracy= 0.976000011\n",
      "Epoch:  39   =====> Loss= 0.086988728\n",
      "Epoch:  39   =====> Validation accuracy= 0.976000011\n",
      "Epoch:  40   =====> Loss= 0.087102949\n",
      "Epoch:  40   =====> Validation accuracy= 0.976999998\n",
      "Epoch:  41   =====> Loss= 0.083360673\n",
      "Epoch:  41   =====> Validation accuracy= 0.975799978\n",
      "Epoch:  42   =====> Loss= 0.084022923\n",
      "Epoch:  42   =====> Validation accuracy= 0.976199985\n",
      "Epoch:  43   =====> Loss= 0.082367388\n",
      "Epoch:  43   =====> Validation accuracy= 0.976999998\n",
      "Epoch:  44   =====> Loss= 0.079504150\n",
      "Epoch:  44   =====> Validation accuracy= 0.977999985\n",
      "Epoch:  45   =====> Loss= 0.080695637\n",
      "Epoch:  45   =====> Validation accuracy= 0.977400005\n",
      "Epoch:  46   =====> Loss= 0.078491434\n",
      "Epoch:  46   =====> Validation accuracy= 0.977999985\n",
      "Epoch:  47   =====> Loss= 0.075237012\n",
      "Epoch:  47   =====> Validation accuracy= 0.977199972\n",
      "Epoch:  48   =====> Loss= 0.075983966\n",
      "Epoch:  48   =====> Validation accuracy= 0.978200018\n",
      "Epoch:  49   =====> Loss= 0.075244751\n",
      "Epoch:  49   =====> Validation accuracy= 0.977400005\n",
      "Epoch:  50   =====> Loss= 0.073928895\n",
      "Epoch:  50   =====> Validation accuracy= 0.978399992\n",
      "Epoch:  51   =====> Loss= 0.073070815\n",
      "Epoch:  51   =====> Validation accuracy= 0.980000019\n",
      "Epoch:  52   =====> Loss= 0.072421110\n",
      "Epoch:  52   =====> Validation accuracy= 0.979600012\n",
      "Epoch:  53   =====> Loss= 0.070736009\n",
      "Epoch:  53   =====> Validation accuracy= 0.980000019\n",
      "Epoch:  54   =====> Loss= 0.068787458\n",
      "Epoch:  54   =====> Validation accuracy= 0.980400026\n",
      "Epoch:  55   =====> Loss= 0.069128410\n",
      "Epoch:  55   =====> Validation accuracy= 0.980400026\n",
      "Epoch:  56   =====> Loss= 0.069190163\n",
      "Epoch:  56   =====> Validation accuracy= 0.978600025\n",
      "Epoch:  57   =====> Loss= 0.067078547\n",
      "Epoch:  57   =====> Validation accuracy= 0.981199980\n",
      "Epoch:  58   =====> Loss= 0.067432549\n",
      "Epoch:  58   =====> Validation accuracy= 0.980599999\n",
      "Epoch:  59   =====> Loss= 0.065485031\n",
      "Epoch:  59   =====> Validation accuracy= 0.980400026\n",
      "Epoch:  60   =====> Loss= 0.065336825\n",
      "Epoch:  60   =====> Validation accuracy= 0.981000006\n",
      "Epoch:  61   =====> Loss= 0.063393976\n",
      "Epoch:  61   =====> Validation accuracy= 0.981599987\n",
      "Epoch:  62   =====> Loss= 0.064113505\n",
      "Epoch:  62   =====> Validation accuracy= 0.980400026\n",
      "Epoch:  63   =====> Loss= 0.062131168\n",
      "Epoch:  63   =====> Validation accuracy= 0.981400013\n",
      "Epoch:  64   =====> Loss= 0.062401009\n",
      "Epoch:  64   =====> Validation accuracy= 0.981000006\n",
      "Epoch:  65   =====> Loss= 0.061758225\n",
      "Epoch:  65   =====> Validation accuracy= 0.980799973\n",
      "Epoch:  66   =====> Loss= 0.060188295\n",
      "Epoch:  66   =====> Validation accuracy= 0.981800020\n",
      "Epoch:  67   =====> Loss= 0.060250902\n",
      "Epoch:  67   =====> Validation accuracy= 0.980799973\n",
      "Epoch:  68   =====> Loss= 0.058864615\n",
      "Epoch:  68   =====> Validation accuracy= 0.982200027\n",
      "Epoch:  69   =====> Loss= 0.058489810\n",
      "Epoch:  69   =====> Validation accuracy= 0.981800020\n",
      "Epoch:  70   =====> Loss= 0.058580324\n",
      "Epoch:  70   =====> Validation accuracy= 0.981000006\n",
      "Epoch:  71   =====> Loss= 0.057326506\n",
      "Epoch:  71   =====> Validation accuracy= 0.983399987\n",
      "Epoch:  72   =====> Loss= 0.057824366\n",
      "Epoch:  72   =====> Validation accuracy= 0.982599974\n",
      "Epoch:  73   =====> Loss= 0.057379467\n",
      "Epoch:  73   =====> Validation accuracy= 0.981800020\n",
      "Epoch:  74   =====> Loss= 0.054802844\n",
      "Epoch:  74   =====> Validation accuracy= 0.981400013\n",
      "Epoch:  75   =====> Loss= 0.055786509\n",
      "Epoch:  75   =====> Validation accuracy= 0.982400000\n",
      "Epoch:  76   =====> Loss= 0.055967308\n",
      "Epoch:  76   =====> Validation accuracy= 0.981999993\n",
      "Epoch:  77   =====> Loss= 0.053248046\n",
      "Epoch:  77   =====> Validation accuracy= 0.982599974\n",
      "Epoch:  78   =====> Loss= 0.054787836\n",
      "Epoch:  78   =====> Validation accuracy= 0.981400013\n",
      "Epoch:  79   =====> Loss= 0.053673725\n",
      "Epoch:  79   =====> Validation accuracy= 0.982999980\n",
      "Epoch:  80   =====> Loss= 0.052092365\n",
      "Epoch:  80   =====> Validation accuracy= 0.982800007\n",
      "Epoch:  81   =====> Loss= 0.054739514\n",
      "Epoch:  81   =====> Validation accuracy= 0.984000027\n",
      "Epoch:  82   =====> Loss= 0.049940518\n",
      "Epoch:  82   =====> Validation accuracy= 0.981999993\n",
      "Epoch:  83   =====> Loss= 0.052808307\n",
      "Epoch:  83   =====> Validation accuracy= 0.981999993\n",
      "Epoch:  84   =====> Loss= 0.050905337\n",
      "Epoch:  84   =====> Validation accuracy= 0.982999980\n",
      "Epoch:  85   =====> Loss= 0.051251687\n",
      "Epoch:  85   =====> Validation accuracy= 0.983399987\n",
      "Epoch:  86   =====> Loss= 0.049719966\n",
      "Epoch:  86   =====> Validation accuracy= 0.984000027\n",
      "Epoch:  87   =====> Loss= 0.049257637\n",
      "Epoch:  87   =====> Validation accuracy= 0.982599974\n",
      "Epoch:  88   =====> Loss= 0.050628482\n",
      "Epoch:  88   =====> Validation accuracy= 0.983399987\n",
      "Epoch:  89   =====> Loss= 0.049123087\n",
      "Epoch:  89   =====> Validation accuracy= 0.984399974\n",
      "Epoch:  90   =====> Loss= 0.048541897\n",
      "Epoch:  90   =====> Validation accuracy= 0.982999980\n",
      "Epoch:  91   =====> Loss= 0.047466213\n",
      "Epoch:  91   =====> Validation accuracy= 0.984000027\n",
      "Epoch:  92   =====> Loss= 0.047182127\n",
      "Epoch:  92   =====> Validation accuracy= 0.983799994\n",
      "Epoch:  93   =====> Loss= 0.049109218\n",
      "Epoch:  93   =====> Validation accuracy= 0.983399987\n",
      "Epoch:  94   =====> Loss= 0.046680474\n",
      "Epoch:  94   =====> Validation accuracy= 0.984000027\n",
      "Epoch:  95   =====> Loss= 0.047027943\n",
      "Epoch:  95   =====> Validation accuracy= 0.983600020\n",
      "Epoch:  96   =====> Loss= 0.045391369\n",
      "Epoch:  96   =====> Validation accuracy= 0.984200001\n",
      "Epoch:  97   =====> Loss= 0.047758072\n",
      "Epoch:  97   =====> Validation accuracy= 0.982999980\n",
      "Epoch:  98   =====> Loss= 0.044372558\n",
      "Epoch:  98   =====> Validation accuracy= 0.983399987\n",
      "Epoch:  99   =====> Loss= 0.045625507\n",
      "Epoch:  99   =====> Validation accuracy= 0.983200014\n",
      "Epoch:  100   =====> Loss= 0.046040000\n",
      "Epoch:  100   =====> Validation accuracy= 0.984399974\n",
      "Accuracy: 0.9831\n",
      "Optimization Finished!\n",
      "Training Finished!\n",
      "Start Training!\n",
      "Epoch:  01   =====> Loss= 0.227796199\n",
      "Epoch:  01   =====> Validation accuracy= 0.976000011\n",
      "Epoch:  02   =====> Loss= 0.073778042\n",
      "Epoch:  02   =====> Validation accuracy= 0.981999993\n",
      "Epoch:  03   =====> Loss= 0.051571053\n",
      "Epoch:  03   =====> Validation accuracy= 0.985400021\n",
      "Epoch:  04   =====> Loss= 0.041520423\n",
      "Epoch:  04   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  05   =====> Loss= 0.032882296\n",
      "Epoch:  05   =====> Validation accuracy= 0.986400008\n",
      "Epoch:  06   =====> Loss= 0.029796373\n",
      "Epoch:  06   =====> Validation accuracy= 0.988399982\n",
      "Epoch:  07   =====> Loss= 0.022257481\n",
      "Epoch:  07   =====> Validation accuracy= 0.989199996\n",
      "Epoch:  08   =====> Loss= 0.020315165\n",
      "Epoch:  08   =====> Validation accuracy= 0.989000022\n",
      "Epoch:  09   =====> Loss= 0.016349035\n",
      "Epoch:  09   =====> Validation accuracy= 0.988200009\n",
      "Epoch:  10   =====> Loss= 0.015238119\n",
      "Epoch:  10   =====> Validation accuracy= 0.986999989\n",
      "Epoch:  11   =====> Loss= 0.014339349\n",
      "Epoch:  11   =====> Validation accuracy= 0.990999997\n",
      "[EPOCH 11] Reached validation accuracy > 99% , stopping training\n",
      "Accuracy: 0.9897\n",
      "Optimization Finished!\n",
      "Training Finished!\n",
      "Batch size: 128\n",
      "Start Training!\n",
      "Epoch:  01   =====> Loss= 2.288126385\n",
      "Epoch:  01   =====> Validation accuracy= 0.265199989\n",
      "Epoch:  02   =====> Loss= 2.220405342\n",
      "Epoch:  02   =====> Validation accuracy= 0.452800006\n",
      "Epoch:  03   =====> Loss= 2.115539384\n",
      "Epoch:  03   =====> Validation accuracy= 0.552200019\n",
      "Epoch:  04   =====> Loss= 1.856719836\n",
      "Epoch:  04   =====> Validation accuracy= 0.639800012\n",
      "Epoch:  05   =====> Loss= 1.318035802\n",
      "Epoch:  05   =====> Validation accuracy= 0.750000000\n",
      "Epoch:  06   =====> Loss= 0.852118183\n",
      "Epoch:  06   =====> Validation accuracy= 0.818799973\n",
      "Epoch:  07   =====> Loss= 0.625621594\n",
      "Epoch:  07   =====> Validation accuracy= 0.852999985\n",
      "Epoch:  08   =====> Loss= 0.510849240\n",
      "Epoch:  08   =====> Validation accuracy= 0.873799980\n",
      "Epoch:  09   =====> Loss= 0.444855042\n",
      "Epoch:  09   =====> Validation accuracy= 0.888199985\n",
      "Epoch:  10   =====> Loss= 0.396212428\n",
      "Epoch:  10   =====> Validation accuracy= 0.897400022\n",
      "Epoch:  11   =====> Loss= 0.370589256\n",
      "Epoch:  11   =====> Validation accuracy= 0.902199984\n",
      "Epoch:  12   =====> Loss= 0.348855811\n",
      "Epoch:  12   =====> Validation accuracy= 0.904999971\n",
      "Epoch:  13   =====> Loss= 0.325868624\n",
      "Epoch:  13   =====> Validation accuracy= 0.909799993\n",
      "Epoch:  14   =====> Loss= 0.319108795\n",
      "Epoch:  14   =====> Validation accuracy= 0.914200008\n",
      "Epoch:  15   =====> Loss= 0.298767135\n",
      "Epoch:  15   =====> Validation accuracy= 0.916199982\n",
      "Epoch:  16   =====> Loss= 0.292946934\n",
      "Epoch:  16   =====> Validation accuracy= 0.919399977\n",
      "Epoch:  17   =====> Loss= 0.279612014\n",
      "Epoch:  17   =====> Validation accuracy= 0.923799992\n",
      "Epoch:  18   =====> Loss= 0.274994077\n",
      "Epoch:  18   =====> Validation accuracy= 0.923799992\n",
      "Epoch:  19   =====> Loss= 0.263344889\n",
      "Epoch:  19   =====> Validation accuracy= 0.927600026\n",
      "Epoch:  20   =====> Loss= 0.257055762\n",
      "Epoch:  20   =====> Validation accuracy= 0.927600026\n",
      "Epoch:  21   =====> Loss= 0.248018277\n",
      "Epoch:  21   =====> Validation accuracy= 0.931999981\n",
      "Epoch:  22   =====> Loss= 0.245682040\n",
      "Epoch:  22   =====> Validation accuracy= 0.935800016\n",
      "Epoch:  23   =====> Loss= 0.236846495\n",
      "Epoch:  23   =====> Validation accuracy= 0.936800003\n",
      "Epoch:  24   =====> Loss= 0.228177382\n",
      "Epoch:  24   =====> Validation accuracy= 0.938199997\n",
      "Epoch:  25   =====> Loss= 0.222381004\n",
      "Epoch:  25   =====> Validation accuracy= 0.938399971\n",
      "Epoch:  26   =====> Loss= 0.218850537\n",
      "Epoch:  26   =====> Validation accuracy= 0.941600025\n",
      "Epoch:  27   =====> Loss= 0.212966231\n",
      "Epoch:  27   =====> Validation accuracy= 0.942600012\n",
      "Epoch:  28   =====> Loss= 0.211057157\n",
      "Epoch:  28   =====> Validation accuracy= 0.945800006\n",
      "Epoch:  29   =====> Loss= 0.197516637\n",
      "Epoch:  29   =====> Validation accuracy= 0.945400000\n",
      "Epoch:  30   =====> Loss= 0.199796671\n",
      "Epoch:  30   =====> Validation accuracy= 0.947399974\n",
      "Epoch:  31   =====> Loss= 0.195282052\n",
      "Epoch:  31   =====> Validation accuracy= 0.948599994\n",
      "Epoch:  32   =====> Loss= 0.188116752\n",
      "Epoch:  32   =====> Validation accuracy= 0.949800014\n",
      "Epoch:  33   =====> Loss= 0.186976419\n",
      "Epoch:  33   =====> Validation accuracy= 0.951399982\n",
      "Epoch:  34   =====> Loss= 0.181973565\n",
      "Epoch:  34   =====> Validation accuracy= 0.952600002\n",
      "Epoch:  35   =====> Loss= 0.175978789\n",
      "Epoch:  35   =====> Validation accuracy= 0.952799976\n",
      "Epoch:  36   =====> Loss= 0.176768297\n",
      "Epoch:  36   =====> Validation accuracy= 0.952799976\n",
      "Epoch:  37   =====> Loss= 0.171138968\n",
      "Epoch:  37   =====> Validation accuracy= 0.954999983\n",
      "Epoch:  38   =====> Loss= 0.165853402\n",
      "Epoch:  38   =====> Validation accuracy= 0.954800010\n",
      "Epoch:  39   =====> Loss= 0.168465412\n",
      "Epoch:  39   =====> Validation accuracy= 0.955999970\n",
      "Epoch:  40   =====> Loss= 0.161565110\n",
      "Epoch:  40   =====> Validation accuracy= 0.955200016\n",
      "Epoch:  41   =====> Loss= 0.154276144\n",
      "Epoch:  41   =====> Validation accuracy= 0.957000017\n",
      "Epoch:  42   =====> Loss= 0.160411254\n",
      "Epoch:  42   =====> Validation accuracy= 0.956799984\n",
      "Epoch:  43   =====> Loss= 0.152816097\n",
      "Epoch:  43   =====> Validation accuracy= 0.958999991\n",
      "Epoch:  44   =====> Loss= 0.147717698\n",
      "Epoch:  44   =====> Validation accuracy= 0.958199978\n",
      "Epoch:  45   =====> Loss= 0.148417664\n",
      "Epoch:  45   =====> Validation accuracy= 0.959200025\n",
      "Epoch:  46   =====> Loss= 0.147474695\n",
      "Epoch:  46   =====> Validation accuracy= 0.961000025\n",
      "Epoch:  47   =====> Loss= 0.142436368\n",
      "Epoch:  47   =====> Validation accuracy= 0.961600006\n",
      "Epoch:  48   =====> Loss= 0.140552042\n",
      "Epoch:  48   =====> Validation accuracy= 0.963000000\n",
      "Epoch:  49   =====> Loss= 0.138032218\n",
      "Epoch:  49   =====> Validation accuracy= 0.962800026\n",
      "Epoch:  50   =====> Loss= 0.137052494\n",
      "Epoch:  50   =====> Validation accuracy= 0.963000000\n",
      "Epoch:  51   =====> Loss= 0.136277265\n",
      "Epoch:  51   =====> Validation accuracy= 0.964200020\n",
      "Epoch:  52   =====> Loss= 0.131455645\n",
      "Epoch:  52   =====> Validation accuracy= 0.962800026\n",
      "Epoch:  53   =====> Loss= 0.131786747\n",
      "Epoch:  53   =====> Validation accuracy= 0.964999974\n",
      "Epoch:  54   =====> Loss= 0.128378577\n",
      "Epoch:  54   =====> Validation accuracy= 0.963599980\n",
      "Epoch:  55   =====> Loss= 0.129998586\n",
      "Epoch:  55   =====> Validation accuracy= 0.964999974\n",
      "Epoch:  56   =====> Loss= 0.126130728\n",
      "Epoch:  56   =====> Validation accuracy= 0.965600014\n",
      "Epoch:  57   =====> Loss= 0.123591207\n",
      "Epoch:  57   =====> Validation accuracy= 0.965200007\n",
      "Epoch:  58   =====> Loss= 0.123820034\n",
      "Epoch:  58   =====> Validation accuracy= 0.966600001\n",
      "Epoch:  59   =====> Loss= 0.119457868\n",
      "Epoch:  59   =====> Validation accuracy= 0.967599988\n",
      "Epoch:  60   =====> Loss= 0.118549236\n",
      "Epoch:  60   =====> Validation accuracy= 0.966199994\n",
      "Epoch:  61   =====> Loss= 0.120547150\n",
      "Epoch:  61   =====> Validation accuracy= 0.967400014\n",
      "Epoch:  62   =====> Loss= 0.115672071\n",
      "Epoch:  62   =====> Validation accuracy= 0.967800021\n",
      "Epoch:  63   =====> Loss= 0.116745418\n",
      "Epoch:  63   =====> Validation accuracy= 0.968400002\n",
      "Epoch:  64   =====> Loss= 0.114839247\n",
      "Epoch:  64   =====> Validation accuracy= 0.967999995\n",
      "Epoch:  65   =====> Loss= 0.112026026\n",
      "Epoch:  65   =====> Validation accuracy= 0.968599975\n",
      "Epoch:  66   =====> Loss= 0.111117331\n",
      "Epoch:  66   =====> Validation accuracy= 0.969399989\n",
      "Epoch:  67   =====> Loss= 0.110832570\n",
      "Epoch:  67   =====> Validation accuracy= 0.969600022\n",
      "Epoch:  68   =====> Loss= 0.107320988\n",
      "Epoch:  68   =====> Validation accuracy= 0.969600022\n",
      "Epoch:  69   =====> Loss= 0.108705018\n",
      "Epoch:  69   =====> Validation accuracy= 0.968999982\n",
      "Epoch:  70   =====> Loss= 0.107163755\n",
      "Epoch:  70   =====> Validation accuracy= 0.969600022\n",
      "Epoch:  71   =====> Loss= 0.105460854\n",
      "Epoch:  71   =====> Validation accuracy= 0.971000016\n",
      "Epoch:  72   =====> Loss= 0.104507970\n",
      "Epoch:  72   =====> Validation accuracy= 0.970600009\n",
      "Epoch:  73   =====> Loss= 0.104423167\n",
      "Epoch:  73   =====> Validation accuracy= 0.972800016\n",
      "Epoch:  74   =====> Loss= 0.103204462\n",
      "Epoch:  74   =====> Validation accuracy= 0.970799983\n",
      "Epoch:  75   =====> Loss= 0.101263313\n",
      "Epoch:  75   =====> Validation accuracy= 0.972400010\n",
      "Epoch:  76   =====> Loss= 0.101506186\n",
      "Epoch:  76   =====> Validation accuracy= 0.972400010\n",
      "Epoch:  77   =====> Loss= 0.098204568\n",
      "Epoch:  77   =====> Validation accuracy= 0.973399997\n",
      "Epoch:  78   =====> Loss= 0.099277446\n",
      "Epoch:  78   =====> Validation accuracy= 0.972400010\n",
      "Epoch:  79   =====> Loss= 0.097762749\n",
      "Epoch:  79   =====> Validation accuracy= 0.972599983\n",
      "Epoch:  80   =====> Loss= 0.095253410\n",
      "Epoch:  80   =====> Validation accuracy= 0.974200010\n",
      "Epoch:  81   =====> Loss= 0.098906882\n",
      "Epoch:  81   =====> Validation accuracy= 0.971199989\n",
      "Epoch:  82   =====> Loss= 0.094332840\n",
      "Epoch:  82   =====> Validation accuracy= 0.973599970\n",
      "Epoch:  83   =====> Loss= 0.093046494\n",
      "Epoch:  83   =====> Validation accuracy= 0.974600017\n",
      "Epoch:  84   =====> Loss= 0.093763692\n",
      "Epoch:  84   =====> Validation accuracy= 0.973800004\n",
      "Epoch:  85   =====> Loss= 0.093284312\n",
      "Epoch:  85   =====> Validation accuracy= 0.974399984\n",
      "Epoch:  86   =====> Loss= 0.094090166\n",
      "Epoch:  86   =====> Validation accuracy= 0.974600017\n",
      "Epoch:  87   =====> Loss= 0.092498529\n",
      "Epoch:  87   =====> Validation accuracy= 0.974799991\n",
      "Epoch:  88   =====> Loss= 0.087953579\n",
      "Epoch:  88   =====> Validation accuracy= 0.975399971\n",
      "Epoch:  89   =====> Loss= 0.091167584\n",
      "Epoch:  89   =====> Validation accuracy= 0.975799978\n",
      "Epoch:  90   =====> Loss= 0.087587558\n",
      "Epoch:  90   =====> Validation accuracy= 0.976199985\n",
      "Epoch:  91   =====> Loss= 0.088841246\n",
      "Epoch:  91   =====> Validation accuracy= 0.976199985\n",
      "Epoch:  92   =====> Loss= 0.088448823\n",
      "Epoch:  92   =====> Validation accuracy= 0.975600004\n",
      "Epoch:  93   =====> Loss= 0.086122345\n",
      "Epoch:  93   =====> Validation accuracy= 0.975799978\n",
      "Epoch:  94   =====> Loss= 0.086105982\n",
      "Epoch:  94   =====> Validation accuracy= 0.977599978\n",
      "Epoch:  95   =====> Loss= 0.087789516\n",
      "Epoch:  95   =====> Validation accuracy= 0.976400018\n",
      "Epoch:  96   =====> Loss= 0.085240507\n",
      "Epoch:  96   =====> Validation accuracy= 0.977999985\n",
      "Epoch:  97   =====> Loss= 0.084157124\n",
      "Epoch:  97   =====> Validation accuracy= 0.977199972\n",
      "Epoch:  98   =====> Loss= 0.084539732\n",
      "Epoch:  98   =====> Validation accuracy= 0.976999998\n",
      "Epoch:  99   =====> Loss= 0.082780621\n",
      "Epoch:  99   =====> Validation accuracy= 0.976800025\n",
      "Epoch:  100   =====> Loss= 0.082101545\n",
      "Epoch:  100   =====> Validation accuracy= 0.977999985\n",
      "Accuracy: 0.9747\n",
      "Optimization Finished!\n",
      "Training Finished!\n",
      "Start Training!\n",
      "Epoch:  01   =====> Loss= 0.348884609\n",
      "Epoch:  01   =====> Validation accuracy= 0.968200028\n",
      "Epoch:  02   =====> Loss= 0.089558067\n",
      "Epoch:  02   =====> Validation accuracy= 0.977999985\n",
      "Epoch:  03   =====> Loss= 0.061880727\n",
      "Epoch:  03   =====> Validation accuracy= 0.984399974\n",
      "Epoch:  04   =====> Loss= 0.048292262\n",
      "Epoch:  04   =====> Validation accuracy= 0.985800028\n",
      "Epoch:  05   =====> Loss= 0.038445203\n",
      "Epoch:  05   =====> Validation accuracy= 0.988200009\n",
      "Epoch:  06   =====> Loss= 0.032730894\n",
      "Epoch:  06   =====> Validation accuracy= 0.989000022\n",
      "Epoch:  07   =====> Loss= 0.028442181\n",
      "Epoch:  07   =====> Validation accuracy= 0.990999997\n",
      "[EPOCH 7] Reached validation accuracy > 99% , stopping training\n",
      "Accuracy: 0.9896\n",
      "Optimization Finished!\n",
      "Training Finished!\n"
     ]
    }
   ],
   "source": [
    "# your answer goes here\n",
    "iterations = 100\n",
    "for lr in [0.0001, 0.001]:\n",
    "    learning_rate = lr\n",
    "    print('Learning rate:', lr)\n",
    "    for bs in [50, 128]:\n",
    "        batch_size = bs\n",
    "        print('Batch size:', bs)\n",
    "        train('./models/lenet5_sgd_relu_' + str(bs) + '_' + str(lr), activation='relu')\n",
    "        train('./models/lenet5_adam_relu_' + str(bs) + '_' + str(lr), optimizer='AdamOptimizer', activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAFwCAYAAAC2Dc0HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ed2ea58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# evenly sampled time at 200ms intervals\n",
    "x = (1, 2, 3, 4)\n",
    "x_labels = ['', '(lr: 0.0001, bs: 50)', '(lr: 0.0001, bs: 128)', '(lr: 0.001, bs: 50)', '(lr: 0.001, bs: 128)', '']\n",
    "t_sgd = [0.9337, 0.8948, 0.9831, 0.9747]\n",
    "t_adam = [0.098, 0.9899, 0.9897, 0.9896]\n",
    "\n",
    "# red dashes, blue squares and green triangles\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.plot(x, t_sgd, 'rd')\n",
    "ax.plot(x, t_adam, 'bs')\n",
    "width = 0.4\n",
    "ax.set_xlim([0, 5])\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.legend(['SGD', 'Adam'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Answer:</strong> In general, the Adam optimizer seems to achieve better results than SGD despite some stability issues (training loss can turn to NaN). In general, the Adam optimizer achieved 99% validation accuracy with the following parameters: (lr: 0.001, bs: 128) after 7 epochs, (lr: 0.001, bs: 50) after 11 epochs, (lr: 0.0001, bs: 128) after 70 epochs. We stopped the optimization process whenever we achieved 99% accuracy in order to speed up the whole evaluation. Moreover, the accuracies were not always stable. We therefore secured good results. Looking at the evaluation carried out, we find that the Adam Optimizer with a learning rate of 0.001 and a batch size of 128 is the best setting (fastest in achieving a 99% validation accuracy). To achieve the same result on the test data we need to run it a little longer though (test accuracy was only 0.9899 after directly stopping the script)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.2.2 </b>  What about applying a dropout layer on the Fully conntected layer and then retraining the model with the best Optimizer and parameters(Learning rate and Batsh size) obtained in *Question 2.2.1*  ? (probability to keep units=0.75). For this stage ensure that the keep prob is set to 1.0 to evaluate the \n",
    "performance of the network including all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your implementaion goes here\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "iterations = 100\n",
    "train('./models/lenet5_adam_relu_drop', optimizer='AdamOptimizer', activation='relu', kp=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Your comments go here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
